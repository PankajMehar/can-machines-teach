---
title: "CMT"
author: "hw"
date: "November 9, 2018"
output: html_document
---

# IMPLEMENTING A UNIVERSAL TEACHING MACHINE

How might we approach designing such a system.

**High level video of all the components in the abstract**
## Problem Formulation

Let's begin our investigation by breaking down our high-level goal into a few sub-goals and we will then take a close look at each of them.

In order to create a concrete digital educational user footprint and journey: 


1. **LEARNING + FEEDBACK** -- given a user consumes a piece of educational material, reliably evaluate their knowledge and provide the feedback for improvement. (credibility, rigour) 

2. **KNOWLEDGE ARCHITECT** -- given a piece of educational content, classify it within a knowledge graph. (relatibility, predictability)


3. **MISSION MAPPING ** -- given multiple student journeys, create a way to customize their own growth journey while offereing a way for them them to compare, connect with and follow, other's journey (compare, traverse, curiosity)


4. **SOCIAL BADGE** -- given a student journey, collapse it into a representative symbol(s) to help validate the progress (digital education footprint) [dimensionality reducing (i.e. time, )] (relatibility, stable but evolving system )

In order to create a adequate system that can take on this mission and vision that we shared above, much of it (1, 2) have been made possible with the recent breakthoughs in deep learning. A few cases like (3,4) may require a more advanced deep learning architecture that has been proposed yet to our knowledge. Let's first take a look at some methods that might come handy when tackling our problem.



## Why deep learning? 

If you look closely at each set of questions that we listed above, it is not hard to find that those questions are solvable by the machines. Let's take the first problem as an example, to create a learning and evaluation system we need to somehow find the connection of the educational material we provided and the meaningful and reliable question & answer set that is associated with the content. In other words, our problem could be simplified as trying to find a function that is able to learn the relationship between our input and output and appropriately map the input to the desired output with this function. 

To the best of our knowledge, deep learning seems to be one of the best techniques currently developed that is able to tackle such a fuzzy issue. First of all, deep learning is known as one of the most flexible machine learning algorithms that can learn and map the **deep representation** from the data and in turn contribute to our unique set of problems i.e. automatic question and answer gnerating or visual question answering problems. Moreover, by leveraging neural network architecture, deep nueral networks architecture can be composed into a single differentiable function and trained end-to-end and they can help identify the suitable *inductive* *biases* catered to the input data type. 

## Before we start...

With the belief that we can and we will find a solution for such a Teaching machine, we are set out to find the possible solutions. As what we discussed above, one of the possible and optimal solutions so far is using current state-of-art deep learning frameworks in related domains for such difficult tasks. Here I will walk you through some thought provinking research findings in a form of survey. 

 To best illustrate the problem and possible solutions, I will reduce the complexity of the problem for now. Keep in mind that our ultimate goal is to be able to use our system in any type of online available educational material. For now, we will just focus on one of the most popular ones - Video educational content.  


# LEARNING + FEEDBACK

First question first, as we described above, we have to ask ourselves before deisgn such a system:

 >"how can we take a piece of educational material (i.e. video/ audio recording or e-book) and properly evaluate their learning and provide some effective feedbacks?". 
 
 Among all the possible evaluation and feedback approaches, *Question&Answering* framework seems to be one of the most common options.
 
 In achieving this task, it requires a hybrid system that can take the media in use as the input and generate a set of meaningful and relevant question and answer pairs as the output.


In terms of question generation, if the questions generated are close-ended (i.e. multi-choice question), the answers can be defined easily. In turn, the evaluation is relatively easy to accomplish for our system.

To promote the best learning experience and optimal learning outcome, a set of well-diversed questions have to be used to test our user's knowledge. That is to say, it is necessary to also include open-ended questions i.e. please summarize this video in 300 words into our question and answer pool.

## Question Generation

The goal of an automatic question generation is to generate a question Q that is syntactically and semantically correct, relevant to the context and meaningful to answer. 

In order to achieve this goal,, we need to train an algorithm to learn the underlying conditional probability distribution $P_{\theta}(Q|X)$ parametrized by $\theta$. Or in other words, we can think of this problem is the one to learn a model $\theta$ during training using text-question pairs so that the probability $P_{\theta}(Q|P)$ is maximized over the given training dataset. 

** Case Studies** 
1. We can think  of it as a seq2seq learning problem; In this paper [QG-Net: A Data-Driven Question Generation Model for Educational Content](http://www.princeton.edu/~shitingl/papers/18l@s-qgen.pdf). They use a bi-directional LSTM network to process the input context words sequence. Encoding the answer into context word vectors.

QG-Net generates questions by iteratively sampling question words from the conditional probability distribution $P(Q|C,A,\theta)$ where $\theta$ denotes the set of parameters. In order to construct the probability distribution, they first create a **context reader** that process each word $c_j$ in the input context and turns it into a fix-sized representation $h_j$

Then, they used a **question generator** generates the question text word-by-word, given all context word representation and all question words in previous time steps. 

As for the quantitative evaluation, they aimed to minimize the difference between the generated question and the true question in the training set during training. Also, they used the standard back-propagation through time with the mini-batch stochastic gradient descent algorithm to learn the model parameters. They employed teacher forcing procedure for training LSTMs. To enhance performance, they also implemented beam search, a greedy but effective approximation to exhausitively search and select the top 25 cancidate output question sentences. The final one would be the one with the lowest negative log likelihood. 

The general QG-Net model Architecture is as below: 


![ma](img/qgnet.png)



2. In this summary [Learning to Ask](http://www.cs.cornell.edu/~xdu/papers/acl17_dsc_poster.pdf), they used a sentence- and paragraph-level seq2seq model to read text from the input content and to generate a question about the input sentence. 

For the second option, we need to encode both sentence and paragraph that sentence belongs to as input, but only attending source sentence hidden states. The performance could be improved with beam search and UNK replacement. 


3. In this paper [TOPIC-BASED QUESTION GENERATION](https://openreview.net/pdf?id=rk3pnae0b), they proposed a topic-based question generation algorithm. The algorithm will be able to take in a input sentence, a topic and a question type; then generate a word sequence related to the topic, question type and the input sentence. 

  They are formulating a conditional likelihood objective function to achieve this goal. 

  Also, in the paper, they proposed a few frameworks that were used to tackle this problem. The first type   is seq2seq model. This model typically uses a bidirectional LSTM as the encoder to encode a sentence and a   LSTM as the decoder to generate the target question. 
  The second approach is question pattern prediction and question topic selection algorithms. It takes in an   automatically selected phrase Q and fill this phrase into the pattern that was predicted from pre-mined   patterns, which is not done with deep learning. 

  The last approach is multi-source seq2seq learning which aims to integrate information from multiple sources to boost learning. 



4. In this paper [A Framework for Automatic Question Generation from Text
using Deep Reinforcement Learning](https://arxiv.org/pdf/1808.04961.pdf) they proposed a novel way of solving this problem in which they used a reinforcement learning framework that consists of a generator and an evaluator. 

They refer to the generator as the $agent$ and the $action$ of the agent is to generate the next work in the question. The probability of decoding a word $P_{\theta}(word)$ gives a stochastic policy. 

The evaluator will in turn assign a reward for the output sequence predicted using the current policy of the generator. Based on the reward assigned by the evaluator, the generator updates and improves its current policy. The goal in RL-based question generation is to find a policy that can maximize the sum of the expected return at the end of the sequence generated. 

## Answer Evaluation 
### Close-ended Questions

**Visual Question Answering (VQA)**

As what we have discussed above, most question focuses solely on generating proper questions but not the answers. 

VQA aims to enable the machine to answer the question automatically which could in turn automated the whole question generating and evaluation process. 


Started from the question-guided attention mechanism that can adaptively learn the most relevant image regions for a given question. Then to stack multiple question-guided attention mechanisms to learn the attention in an iterative way. Also, it is possible to use bilinear features to integrate the visual features from the image spatial grids with question features to predict attention.

Considering the questions in natural language may also contain some noise, the co-attention mechanism can jointly learn the attention for both the image and question.


1. In this paper [Deep Attention Neural Tensor Network for
Visual Question Answering](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.pdf),

![ma](img/vqa.png)

2. In this paper [Question Type Guided Attention in Visual Question
Answering](https://arxiv.org/pdf/1804.02088.pdf), they proposed a model called Question Type-guided Attention (QTA). This model utilizes the information of question type to dynamically balance visual features from both top-down and bottom-up orders. Meanwhile, it has a novel neural architecture that dynamically gates the conribution of ResNet and Faster R-CNN features based on the question type.

#### Dual Question-Answering Model

Both Question Generaion(QG) and Question Answering(QA) are well-defined 2 sets of models that aim to either infer a question or an answer given the counterpart based on the context. However, our goal is to have a complete automated system that can take on both roles simultaneously for us.  

There are some algorithms are designed to fulfill both roles. 

1.In this paper [Dual Ask-Answer Network for Machine Reading Comprehension](https://arxiv.org/pdf/1809.01997.pdf) they presented a model that can learn question answering and question generation simultaneousely. 

The idea is illustrate as below: 
![qgqa](img/qgqa.png)

![daan](img/daan.png)


2. In this paper [Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia](https://arxiv.org/pdf/1805.05942.pdf),  they applied their question-answer pair generation system to 10000 top-ranking Wikipedia articles and create over a million question-answer pairs. 

In their task formulation part, they mentioned that they break this task into 2 sub-tasks: 


* candidate answer extraction 

* answer-specific question generation 




3. In this paper [Visual Question Generation as Dual Task of Visual Question Answering](http://cvboy.com/pdf/publications/cvpr2018_iqan.pdf), they proposed an end-to-end unified model, Invertible Question Answering (iQAN) to introduce question generation as a dual task of question answering to imrpove VQA pefromance. 

### Open-ended Question
#### General Question
As I mentioned aboce, one of the most general open-ended questions is to ask user to provide a short summary of the learning material. 

At the first glance, it appears hard for our system to effectively evaluate the answers. However, this type of task is not that far-fetched by using some specifically designed deep learning frameworks.

#### Specific Question
As for the automated feedback or learning grading system, there are plenty of suggestions have been proposed as well to tackle such a question. The framework is called automated essay scoring (AES) which focuses on automatically analyzing the quality of writing and assigning a score to the text. 

In terms of knowledge or learning evaluation, the format could be diversed i.e. a lecture given by the student or an short summary essay written by the student. Regardless the form, we can always convert the content into a predictable text, graphic or audible format that model can process. 

As we mentioned above, for these type of task, we can implementing RNN to process the content and even enhance the model performance by adversarially craft input as this paper [Neural Automated Essay Scoring and Coherence Modeling for
Adversarially Crafted Input](http://aclweb.org/anthology/N18-1024) illustrated.



# KNOWLEDGE ARCHITECT
Next, we need to consider how we can select an adequate and relevant learning masterial and generate an effecive learning map for the users based on their current progress and the general knowledge graph/map, given the ever growing amount of educational content on the web. 

As I mentioned earlier, learning is a knowledge accumulation process. Knowledge itself has its unique structure that can help us learn in a most effective and productive way. Knowledge Graph is a great tool that we developed to map and present the structure of knolwedge. In shirt, knowledge graphs are collections of relational facts, where each fact states that a certrain relation holds between 2 entities.

In this paper [Generalized Embedding Model for Knowledge Graph Mining](http://www.mlgworkshop.org/2018/papers/MLG2018_paper_5.pdf), they have presented a model for learning neural presentation of generalized knowledge graphs using a novel muli-shot unsupervised neural network model, called the **Graph Embedding Network (GEN)**. This model is able to learn different types of knowlege graphs from a universal perspective and it provides flexibility in learning representations that work on graphs conforming to different domains. 


In this paper [Probabilisic Knowledge Graph Embeddings](https://openreview.net/pdf?id=rJ4qXnCqFX), they explored a new type of embedding model that can link prediction in relational knowledge graph. 


# MISSION MAPPING 

The knowledge graph is our ground truth and can be applied universally to some extent, but everyone's learning journey is still highly personal and custom. In terms of learning, everyone seems to have their unique set of problems that they are curious about and everyone is on their own mission towards the mastery.

We cannot possibly put such an online learning/teaching system into use without taking this crucial factor into our account. In order to put our hands on this set of problems, we can rely on some heuristic and models that have been developed to resolve this type of idiosymcratic issue.


As we all know that a recommender system is an intuitive line of defense against consumer over-choice given the evern growing information available on the web. As we mentioned earlier in the knowledge graph, a authoritative and personalized recommending system is essential for facilitating the learning. 

Typically, a recommendation models can be classified into 3 main categories: 


1. Collaborative filtering


2. Content based 


3. Hybrid recommender system 

As I mentioned, here we will mainly focus on hybrid recommender system. 

There are a diverse array of achitectual paradigms that are closely related recommending system. Let's take a look at few of them: 
1. Autoencoder 


2. Convolutional Neural Network 


3. Recurrent Neural Network 


4. Restricted Boltzmann Machine (RBM)


5. Adversarial Networks


6. Attentional Models (AM)


7. Deep Reinforcement Learning (DRL)




**Reference** 


1. [A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning](https://arxiv.org/pdf/1808.04961.pdf)


2. [Learning to Ask: Neural Question Generation for Reading Comprehension](https://arxiv.org/pdf/1705.00106.pdf)


3. [Deep Attention Neural Tensor Network for Visual Question Answering](http://openaccess.thecvf.com/content_ECCV_2018/papers/Yalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.pdf)


4. [Learning to Ask](http://www.cs.cornell.edu/~xdu/papers/acl17_dsc_poster.pdf)


5. [TOPIC-BASED QUESTION GENERATION](https://openreview.net/pdf?id=rk3pnae0b)


5. [Deep Learning based Recommender System](https://arxiv.org/pdf/1707.07435.pdf)