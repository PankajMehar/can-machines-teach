<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Teaching Machines - Deep Learning and Education</title>
  <meta name="description" content="Lets start with a future view of an individuals education. Many of us have used the internet to educate ourselves with the abundance of medium to high quality videos, papers, articles, podcasts and how-tos being uploaded from numerous individuals, groups, and institutions like never before. Let us imagine that all of what you have learned online, throughout the entirety of your life, from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you’ve read, watched, or listened to, were all added structurally to your education journey and what if that could be consolidated into what we might call a digital education footprint.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Teaching Machines - Deep Learning and Education" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/dyadxmachina/can-machines-teach" />
  <meta property="og:image" content="https://github.com/dyadxmachina/can-machines-teachimg/MtoQA.png" />
  <meta property="og:description" content="Lets start with a future view of an individuals education. Many of us have used the internet to educate ourselves with the abundance of medium to high quality videos, papers, articles, podcasts and how-tos being uploaded from numerous individuals, groups, and institutions like never before. Let us imagine that all of what you have learned online, throughout the entirety of your life, from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you’ve read, watched, or listened to, were all added structurally to your education journey and what if that could be consolidated into what we might call a digital education footprint." />
  <meta name="github-repo" content="dyadxmachina/can-machines-teach" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Teaching Machines - Deep Learning and Education" />
  
  <meta name="twitter:description" content="Lets start with a future view of an individuals education. Many of us have used the internet to educate ourselves with the abundance of medium to high quality videos, papers, articles, podcasts and how-tos being uploaded from numerous individuals, groups, and institutions like never before. Let us imagine that all of what you have learned online, throughout the entirety of your life, from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you’ve read, watched, or listened to, were all added structurally to your education journey and what if that could be consolidated into what we might call a digital education footprint." />
  <meta name="twitter:image" content="https://github.com/dyadxmachina/can-machines-teachimg/MtoQA.png" />

<meta name="author" content="Fanli (Christian) Zheng &amp; Haohan Wang">


<meta name="date" content="2018-11-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="implementing-the-knowledge-ecosystem.html">
<link rel="next" href="knowledge-graph.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128379860-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128379860-3');
</script>

<!-- Primary Meta Tags -->
<title>Teaching Machines - Artificial Intelligence and Education </title>
<meta name="title" content="Teaching Machines - Artificial Intelligence and Education ">
<meta name="description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="og:title" content="Teaching Machines - Artificial Intelligence and Education learn the math needed to design artificial neural networks">
<meta property="og:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="og:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">


<!-- Primary Meta Tags -->
<title>Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng</title>
<meta name="title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng">
<meta name="description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="og:title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng">
<meta property="og:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="og:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="twitter:title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng">
<meta property="twitter:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="twitter:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="twitter:title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng ">
<meta property="twitter:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="twitter:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Teaching Machines: AI and Education</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#digital-knowledge-footprint"><i class="fa fa-check"></i><b>1.1</b> Digital Knowledge Footprint</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#knowledge-journeys"><i class="fa fa-check"></i><b>1.2</b> Knowledge Journeys</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#collective-human-knowledge-graph"><i class="fa fa-check"></i><b>1.3</b> Collective Human Knowledge Graph</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#deep-learning-applications-in-learning-and-feedback"><i class="fa fa-check"></i><b>1.4</b> Deep Learning Applications in Learning and Feedback</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#summary"><i class="fa fa-check"></i><b>1.4.1</b> Summary</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#ec2qa-network---a-novel-network-for-educational-content-to-questions-and-answers"><i class="fa fa-check"></i><b>1.4.2</b> EC2QA Network - a novel network for educational content to questions and answers</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#passive-consumption"><i class="fa fa-check"></i><b>1.5</b> Passive Consumption</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#untested-knowledge"><i class="fa fa-check"></i><b>1.6</b> Untested Knowledge</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#predictability"><i class="fa fa-check"></i><b>1.7</b> Predictability</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#the-components"><i class="fa fa-check"></i><b>1.8</b> The components</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="implementing-the-knowledge-ecosystem.html"><a href="implementing-the-knowledge-ecosystem.html"><i class="fa fa-check"></i><b>2</b> Implementing the Knowledge Ecosystem</a><ul>
<li class="chapter" data-level="2.1" data-path="implementing-the-knowledge-ecosystem.html"><a href="implementing-the-knowledge-ecosystem.html#problem-formulation"><i class="fa fa-check"></i><b>2.1</b> Problem Formulation</a></li>
<li class="chapter" data-level="2.2" data-path="implementing-the-knowledge-ecosystem.html"><a href="implementing-the-knowledge-ecosystem.html#why-deep-learning"><i class="fa fa-check"></i><b>2.2</b> Why deep learning?</a></li>
<li class="chapter" data-level="2.3" data-path="implementing-the-knowledge-ecosystem.html"><a href="implementing-the-knowledge-ecosystem.html#before-we-start"><i class="fa fa-check"></i><b>2.3</b> Before we start…</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="learning-feedback.html"><a href="learning-feedback.html"><i class="fa fa-check"></i><b>3</b> LEARNING + FEEDBACK</a><ul>
<li class="chapter" data-level="3.1" data-path="learning-feedback.html"><a href="learning-feedback.html#question-generation"><i class="fa fa-check"></i><b>3.1</b> Question Generation</a></li>
<li class="chapter" data-level="3.2" data-path="learning-feedback.html"><a href="learning-feedback.html#answer-evaluation"><i class="fa fa-check"></i><b>3.2</b> Answer Evaluation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="learning-feedback.html"><a href="learning-feedback.html#close-ended-questions"><i class="fa fa-check"></i><b>3.2.1</b> Close-ended Questions</a></li>
<li class="chapter" data-level="3.2.2" data-path="learning-feedback.html"><a href="learning-feedback.html#open-ended-question"><i class="fa fa-check"></i><b>3.2.2</b> Open-ended Question</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="learning-feedback.html"><a href="learning-feedback.html#summary-of-learning-and-feedback-networks"><i class="fa fa-check"></i><b>3.3</b> Summary of Learning and Feedback Networks</a><ul>
<li class="chapter" data-level="3.3.1" data-path="learning-feedback.html"><a href="learning-feedback.html#summary-current-research"><i class="fa fa-check"></i><b>3.3.1</b> summary current research</a></li>
<li class="chapter" data-level="3.3.2" data-path="learning-feedback.html"><a href="learning-feedback.html#areas-where-new-stuff-needs-to-be-made-research-current-reserach-is-promising-but-we-need-more-reserach-and-innovation-in-this-area"><i class="fa fa-check"></i><b>3.3.2</b> areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area]</a></li>
<li class="chapter" data-level="3.3.3" data-path="learning-feedback.html"><a href="learning-feedback.html#datasets-and-annotaters-needed"><i class="fa fa-check"></i><b>3.3.3</b> datasets and annotaters needed</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="knowledge-graph.html"><a href="knowledge-graph.html"><i class="fa fa-check"></i><b>4</b> KNOWLEDGE GRAPH</a><ul>
<li class="chapter" data-level="4.1" data-path="knowledge-graph.html"><a href="knowledge-graph.html#summary-of-knowledge-graph"><i class="fa fa-check"></i><b>4.1</b> Summary of Knowledge Graph</a><ul>
<li class="chapter" data-level="4.1.1" data-path="knowledge-graph.html"><a href="knowledge-graph.html#summary-current-research-1"><i class="fa fa-check"></i><b>4.1.1</b> summary current research</a></li>
<li class="chapter" data-level="4.1.2" data-path="knowledge-graph.html"><a href="knowledge-graph.html#areas-where-new-stuff-needs-to-be-made-research-current-reserach-is-promising-but-we-need-more-reserach-and-innovation-in-this-area-1"><i class="fa fa-check"></i><b>4.1.2</b> areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area]</a></li>
<li class="chapter" data-level="4.1.3" data-path="knowledge-graph.html"><a href="knowledge-graph.html#datasets-and-annotaters-needed-1"><i class="fa fa-check"></i><b>4.1.3</b> datasets and annotaters needed</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="knowledge-journeys-1.html"><a href="knowledge-journeys-1.html"><i class="fa fa-check"></i><b>5</b> KNOWLEDGE JOURNEYS</a></li>
<li class="chapter" data-level="6" data-path="digital-knowledge-footprint-1.html"><a href="digital-knowledge-footprint-1.html"><i class="fa fa-check"></i><b>6</b> DIGITAL KNOWLEDGE FOOTPRINT</a><ul>
<li class="chapter" data-level="6.1" data-path="digital-knowledge-footprint-1.html"><a href="digital-knowledge-footprint-1.html#summary-of-current-research-and-needs"><i class="fa fa-check"></i><b>6.1</b> Summary of Current Research and Needs</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data-and-annotation.html"><a href="data-and-annotation.html"><i class="fa fa-check"></i><b>7</b> Data and Annotation</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dyadxmachina/can-machines-think" target="blank">Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Teaching Machines - Deep Learning and Education</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="learning-feedback" class="section level1">
<h1><span class="header-section-number">3</span> LEARNING + FEEDBACK</h1>
<p>A salient question that we have to ask ourselves before deisgning such a system is that:</p>
<blockquote>
<p>“how can we take a piece of educational content and properly test a learners’ knowledge and provide insightful feedbacksto support their learning?”.</p>
</blockquote>
<p>In previous years, deep learning research has taken up a similar problem titled question answer</p>
<blockquote>
<p>Question answering (QA) is a well-researched problem in NLP. In spite of being one of the oldest research areas, QA has application in a wide variety of tasks, such as information retrieval and entity extraction. Recently, QA has also been used to develop dialog systems [1] and chatbots [2] designed to simulate human conversation. Traditionally, most of the research in this domain used a pipeline of conventional linguistically-based NLP techniques, such as parsing, part-of-speech tagging and coreference resolution. Many of the state-of-the-art QA systems – for example, IBM Watson [3] –use these methods.</p>
</blockquote>
<p>src: <a href="https://cs224d.stanford.edu/reports/StrohMathur.pdf" class="uri">https://cs224d.stanford.edu/reports/StrohMathur.pdf</a></p>
<p>But this usually only fits the answeringissue given a question . What we want to do is take a piece of content and generate a set of questions-answer pairs.</p>
<blockquote>
<p>“what types of questions &amp; answers would be best to test a learner’s knowledge given a piece of educational content (i.e. a lecture video)”</p>
</blockquote>
<p>Let’s say a learner is watching an deducation, then we could n, asking specific questions, or we could allow them to talk abck to us and evaluate their answers. We will approach of these here from the current research and new research needed</p>
<p>So the formulation for both of these is to 1. Generate general question + Answers pairs 2. Generate specific question + Answers pairs - Multiple choice 2. Evaluate and comment on open-ended answers</p>
<p>Here, we carefully split the questions into 2 distinct categories. One is regular close-ended question (i.e. multiple choise question) and the other one is open-ended question (i.e. tell me about your thoughts on this idea discussed in the video).</p>
<p>In terms of the close-ended, the answers can be defined and evaluated easily. However, the process might be a little bit tricky when it comes to the open-ended questions.</p>
<div id="question-generation" class="section level2">
<h2><span class="header-section-number">3.1</span> Question Generation</h2>
<p>First, let’s take a look at question generation (QG) problem on its own.</p>
<p>The ideal goal of an automatic question generation is to generate a question Q that is syntactically and semantically correct, relevant to the context and meaningful to answer.</p>
<p>In order to achieve this goal,, we need to train an algorithm to learn the underlying conditional probability distribution <span class="math display">\[P_{\theta}(Q|X)\]</span> parametrized by <span class="math inline">\(\theta\)</span>. In other words, we can think of this problem as the same one that requires the model learn a function (with a set of parameters) <span class="math inline">\(\theta\)</span> during the training stage using content-question pairs so that the probability <span class="math inline">\(P_{\theta}(Q|P)\)</span> is maximized over the given training dataset.</p>
<p>It is also helpful to frame this problem into a seq2seq learning problem since both the input and the output is most likely a sequence of text character that the model needs to process and learn the relationship from.</p>
<p><strong>Case Studies</strong> 1. In this paper <a href="http://www.princeton.edu/~shitingl/papers/18l@s-qgen.pdf">QG-Net: A Data-Driven Question Generation Model for Educational Content</a>. They use a bi-directional LSTM network to process the input context words sequence. Encoding the answer into context word vectors.</p>
<p>QG-Net generates questions by iteratively sampling question words from the conditional probability distribution <span class="math inline">\(P(Q|C,A,\theta)\)</span> where <span class="math inline">\(\theta\)</span> denotes the set of parameters. In order to construct the probability distribution, they first create a <strong>context reader</strong> that process each word <span class="math inline">\(c_j\)</span> in the input context and turns it into a fix-sized representation <span class="math inline">\(h_j\)</span></p>
<p>Then, they used a <strong>question generator</strong> generates the question text word-by-word, given all context word representation and all question words in previous time steps.</p>
<p>As for the quantitative evaluation, they aimed to minimize the difference between the generated question and the true question in the training set during training. Also, they used the standard back-propagation through time with the mini-batch stochastic gradient descent algorithm to learn the model parameters. They employed teacher forcing procedure for training LSTMs. To enhance performance, they also implemented beam search, a greedy but effective approximation to exhausitively search and select the top 25 cancidate output question sentences. The final one would be the one with the lowest negative log likelihood.</p>
<p>The general QG-Net model Architecture is as below:</p>
<div class="figure">
<img src="img/qgnet.png" alt="ma" />
<p class="caption">ma</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this summary <a href="http://www.cs.cornell.edu/~xdu/papers/acl17_dsc_poster.pdf">Learning to Ask</a>, they used a sentence- and paragraph-level seq2seq model to read text from the input content and to generate a question about the input sentence.</li>
</ol>
<p>For the second option, we need to encode both sentence and paragraph that sentence belongs to as input, but only attending source sentence hidden states. The performance could be improved with beam search and UNK replacement.</p>
<ol start="3" style="list-style-type: decimal">
<li>In this paper <a href="https://openreview.net/pdf?id=rk3pnae0b">TOPIC-BASED QUESTION GENERATION</a>, they proposed a topic-based question generation algorithm. The algorithm will be able to take in a input sentence, a topic and a question type; then generate a word sequence related to the topic, question type and the input sentence.</li>
</ol>
<p>They are formulating a conditional likelihood objective function to achieve this goal.</p>
<p>Also, in the paper, they proposed a few frameworks that were used to tackle this problem. The first type is seq2seq model. This model typically uses a bidirectional LSTM as the encoder to encode a sentence and a LSTM as the decoder to generate the target question.</p>
<p>The second approach is question pattern prediction and question topic selection algorithms. It takes in an automatically selected phrase Q and fill this phrase into the pattern that was predicted from pre-mined patterns, which is not done with deep learning.</p>
<p>The last approach is multi-source seq2seq learning which aims to integrate information from multiple sources to boost learning.</p>
<ol start="4" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1808.04961.pdf">A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning</a> they proposed a novel way of solving this problem in which they used a reinforcement learning framework that consists of a generator and an evaluator.</li>
</ol>
<p>They refer to the generator as the <span class="math inline">\(agent\)</span> and the <span class="math inline">\(action\)</span> of the agent is to generate the next work in the question. The probability of decoding a word <span class="math inline">\(P_{\theta}(word)\)</span> gives a stochastic policy.</p>
<p>The evaluator will in turn assign a reward for the output sequence predicted using the current policy of the generator. Based on the reward assigned by the evaluator, the generator updates and improves its current policy. The goal in RL-based question generation is to find a policy that can maximize the sum of the expected return at the end of the sequence generated.</p>
<p>** Summary **</p>
<p>In this QG section, we have discussed 4 algorithms. They provide us a way to frame our problem for which we can apply generative seq2seq model framework. As for our objective function, we are formuating a conditional probability distribution that is conditioned on the provided content (i.e. the video) and answers. Typically, we can use a bi-directional LSTM as the encoder to encode the content and use a LSTM as the decoder to generate the question.</p>
</div>
<div id="answer-evaluation" class="section level2">
<h2><span class="header-section-number">3.2</span> Answer Evaluation</h2>
<div id="close-ended-questions" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Close-ended Questions</h3>
<p><strong>Visual Question Answering (VQA)</strong></p>
<p>As what we have covered above, most QG problem focuses solely on generating questions but not the answers based on the context.</p>
<p>VQA is a challenging sementic task that focuses on providing a natural language answer given any image and any free-form natural language question. As we are managing to handle the video educational content that is likely to involve language processing and visual recognition tasks, VQA would be a proper and relevant start. By leveraging this type of algorithm, we enable our system to easily evaluate the answer provided by learners which could in turn automated the whole question + answering + evaluation cycle.</p>
<p>Since we are dealing with visual input, question-guided attention mechanism is a key component for solving this type of task. Started from the attention mechanism that can adaptively learn the most relevant image regions for a given question. Then to stack multiple question-guided attention mechanisms to learn the attention in an iterative way. Also, it is possible to use bilinear features to integrate the visual features from the image spatial grids with question features to predict attention. Considering the questions in natural language may also contain some noise, the co-attention mechanism can jointly learn the attention for both the image and question.</p>
<ol style="list-style-type: decimal">
<li>In this paper <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.pdf">Deep Attention Neural Tensor Network for Visual Question Answering</a>, they proposed a novel deep attention neural tensor network that can discover the joint correlation over images, questions and answers with tensor-based representation.</li>
</ol>
<p>As for their workflow, they modeled one of the pairwise interaction (i.e. between image and question) by bilinear features, which is further encoded with the thrid dimension (i.e. answer) to be a triplet using bilinear tensor product. During this step, the model takes in a question + a corresponding image + candidate answers as the input. A CNN (convolutional neural network) a GRU RNN (recurrent neural network) are used for extracting feature vectors and question respectively. Then the representation is passed on as a multi-modal features and integrated by bilinear pooling module. Moreover, they decompose the correlation of triplets by their question and answer types with a slice-wise attention module on tensor to select the most discriminative reasoning process inference.</p>
<p>In the end, they optimize the proposed network by learning a label regression with KL-divergence losses.</p>
<p>They clamined that with these techniques, they can enable scalable training and fast convergence over a large number of answer set.</p>
<p>During the inference stage, they feed the embeddings of all candicate answer into the network and then select the answer which has the biggest triplet relevance socre as the final answer.</p>
<p>The general network architecture is as follows:</p>
<div class="figure">
<img src="img/vqa.png" alt="ma" />
<p class="caption">ma</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1804.02088.pdf">Question Type Guided Attention in Visual Question Answering</a>, they proposed a model called Question Type-guided Attention (QTA). This model utilizes the information of question type to dynamically balance visual features from both top-down and bottom-up orders.</li>
</ol>
<p>Finally, they propose a multi-task extension that is trained to predict question types from the lexical inputs during training which generalizes the network into applications that lack question type, with a minimal performance loss.</p>
<p>As for their main contribution, they focus on developing an attention mechanism that can exploit high-level semantic information on the question type to guide the visual encoding process.</p>
<p>Specifically, they introduced a novel VQA architecture that can dynamically gate the contribution of ResNet and Faster R-CNN features based on the question type. In turn, it allows them to integrate the information from multiple visual sources and obtain gains across all question types. <strong>Summary</strong> By going through the previous examples, we can see that VQA is very particular type of algorithms that is designed to efficiently process image and text input data while making the inference based on the input. Attention is a typical mechanism applied in this type of problems.</p>
<div id="dual-question-answering-model" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Dual Question-Answering Model</h4>
<p>Both Question Generaion(QG) and Question Answering(QA) are well-defined 2 sets of models that aim to either infer a question or an answer given the counterpart based on the context. However, our goal is to have a complete automated system that can take on both roles simultaneously for us.</p>
<p>There are some algorithms are designed to fulfill both roles.</p>
<p>1.In this paper <a href="https://arxiv.org/pdf/1809.01997.pdf">Dual Ask-Answer Network for Machine Reading Comprehension</a> they presented a model that can learn question answering and question generation simultaneousely.</p>
<p>The idea is illustrate as below:</p>
<div class="figure">
<img src="img/qgqa.png" alt="qgqa" />
<p class="caption">qgqa</p>
</div>
<div class="figure">
<img src="img/daan.png" alt="daan" />
<p class="caption">daan</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1805.05942.pdf">Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia</a>, they applied their question-answer pair generation system to 10000 top-ranking Wikipedia articles and create over a million question-answer pairs.</li>
</ol>
<p>In their task formulation part, they mentioned that they break this task into 2 sub-tasks:</p>
<ul>
<li><p>candidate answer extraction</p></li>
<li><p>answer-specific question generation</p></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><p>In this paper <a href="http://cvboy.com/pdf/publications/cvpr2018_iqan.pdf">Visual Question Generation as Dual Task of Visual Question Answering</a>, they proposed an end-to-end unified model, Invertible Question Answering (iQAN) to introduce question generation as a dual task of question answering to imrpove VQA pefromance.</p></li>
<li><p>In this paper <a href="https://arxiv.org/pdf/1709.01058.pdf">A Unified Query-based Generative Model for Question Generation and Question Answering</a>, they propose a query-based generative model for solving both tasks. The model follows the classic encoder-decoder framework. The multi-perspective matching encoder that they are implementing is a bi-directional LSTM RNN model that takes a passage and a query as input and perform query understanding by matching it with the passage from multiple perspectives; The decoder is an attention-based LSTM RNN model with copy and coverage mechanism. In the QG task, a question will be generated from the model given the passge and the target answer, whereas in the QA task, the answer will be generated given the question and the passage. They also leverage a policy-gradient reinforcement learning algorithm to overcome exposure bias (a major problem resulted from sequence learning with cross-entropy loss function).They case both QG and QA tasks into one process by firstly matching the input passage against the query, then generating the output based on the matching results.</p></li>
</ol>
<p>As for the training process, they first pretrain the model with cross-entropy loss and then they fine tune the model parameters with policy-gradient reinforcement learning to alleviate the exposure bias problem. During the policy-gradient reinforcement learning algorithm, they end up adopting a similar sampling strategy as the scheduled sampling strategy for generating the sampled output.</p>
<p><strong>Summary</strong> As what have discussed above, we can see that there have been many attemps taken in the recent years for handling both tasks at the same time and some significant progress have been made.</p>
</div>
</div>
<div id="open-ended-question" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Open-ended Question</h3>
<p>Summary of #### General Question As I mentioned aboce, one of the most general open-ended questions is to ask learner to provide a short summary of the learning material.</p>
<p>At the first glance, it appears hard for our system to effectively evaluate the answers. However, this type of task is not that far-fetched by using some specifically designed deep learning frameworks.</p>
<div id="specific-question" class="section level4">
<h4><span class="header-section-number">3.2.2.1</span> Specific Question</h4>
<p>As for the automated feedback or learning grading system, there are plenty of suggestions have been proposed as well to tackle such a question. The framework is called automated essay scoring (AES) which focuses on automatically analyzing the quality of writing and assigning a score to the text.</p>
<p>In terms of knowledge or learning evaluation, the format could be diversed i.e. a lecture given by the student or an short summary essay written by the student. Regardless the form, we can always convert the content into a predictable text, graphic or audible format that model can process.</p>
<p>As we mentioned above, for these type of task, we can implementing RNN to process the content and even enhance the model performance by adversarially craft input as this paper <a href="http://aclweb.org/anthology/N18-1024">Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input</a> illustrated.</p>
</div>
</div>
</div>
<div id="summary-of-learning-and-feedback-networks" class="section level2">
<h2><span class="header-section-number">3.3</span> Summary of Learning and Feedback Networks</h2>
<div id="summary-current-research" class="section level3">
<h3><span class="header-section-number">3.3.1</span> summary current research</h3>
</div>
<div id="areas-where-new-stuff-needs-to-be-made-research-current-reserach-is-promising-but-we-need-more-reserach-and-innovation-in-this-area" class="section level3">
<h3><span class="header-section-number">3.3.2</span> areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area]</h3>
</div>
<div id="datasets-and-annotaters-needed" class="section level3">
<h3><span class="header-section-number">3.3.3</span> datasets and annotaters needed</h3>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="implementing-the-knowledge-ecosystem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="knowledge-graph.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dyadxmachina/can-machines-teach/edit/master/02-survey.Rmd",
"text": "Edit"
},
"download": ["Teaching Machines - Artificial Intelligence and Education.pdf", "Teaching Machines - Artificial Intelligence and Education.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
