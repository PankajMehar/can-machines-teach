<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Teaching Machines - Artificial Intelligence and Education</title>
  <meta name="description" content="learn the foundational mathematics required to learn and apply cutting edge deep learning techniques. From Aristolean logic to Jaynes theory of probability to Rosenblatt’s Perceptron and Vapnik's Statistical Learning Theory">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Teaching Machines - Artificial Intelligence and Education" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/dyadxmachina/can-machines-teach" />
  <meta property="og:image" content="https://github.com/dyadxmachina/can-machines-teachimg/radar.png" />
  <meta property="og:description" content="learn the foundational mathematics required to learn and apply cutting edge deep learning techniques. From Aristolean logic to Jaynes theory of probability to Rosenblatt’s Perceptron and Vapnik's Statistical Learning Theory" />
  <meta name="github-repo" content="dyadxmachina/can-machines-teach" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Teaching Machines - Artificial Intelligence and Education" />
  
  <meta name="twitter:description" content="learn the foundational mathematics required to learn and apply cutting edge deep learning techniques. From Aristolean logic to Jaynes theory of probability to Rosenblatt’s Perceptron and Vapnik's Statistical Learning Theory" />
  <meta name="twitter:image" content="https://github.com/dyadxmachina/can-machines-teachimg/radar.png" />

<meta name="author" content="Fanli (Christian) Zheng Ramsey &amp; Haohan Wang">


<meta name="date" content="2018-11-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="implementing-a-teaching-machine.html">
<link rel="next" href="knowledge-architect.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128379860-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128379860-3');
</script>

<!-- Primary Meta Tags -->
<title>Teaching Machines - Artificial Intelligence and Education </title>
<meta name="title" content="Teaching Machines - Artificial Intelligence and Education ">
<meta name="description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="og:title" content="Teaching Machines - Artificial Intelligence and Education learn the math needed to design artificial neural networks">
<meta property="og:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="og:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">


<!-- Primary Meta Tags -->
<title>Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng</title>
<meta name="title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng">
<meta name="description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="og:title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng">
<meta property="og:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="og:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="twitter:title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng">
<meta property="twitter:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="twitter:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://dyadxmachina.github.io/can-machines-teach/">
<meta property="twitter:title" content="Teaching Machines - Artificial Intelligence and Education by Haohan Wang and Fanli (Christian) Zheng ">
<meta property="twitter:description" content="Let's start with a future view of an individual's education. Many of us have used the internet to educate ourselves with the abundance of high quality videos, papers, articles, podcasts and how-tos all over the web. Let us imagine that all of what you have learned online (throughout the entirety of your life), from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you've read, watched, or listened to, were all consolidated into what we might call a **digital education footprint**.   The **digital education footprint** would string together our online education into a concrete representation of an individual's online education and could be extended into more formal settings. By showcasing the broad range of individual's knowledge (making digital music) as well as the places they've went deeper than most (deep learning or philosophy of mathematics), we could begin to accept education as a life-long journey rather than one monolithic part of an individual's past. This would begin to show us a more accurate depiction of individual's education that could be updated each and everytime one educates themselves. With every new year, their footprint would evolve just as the very thread of their lives would. Visualised over time, we would be able to see an individual's journey or even a whole communities. Seeing how differen  In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I'll talk about how we can use machine learning and deep learning in particular to help create our **digital education footprint**, **student journeys**, and a collective human knowledge graph. This will allow us to take the space of unstructured educational content and begin to map it unto a knowledge graph and use generative models to make educational content engaging and test a student's knowledge no matter the subject. I will name a few benefits of such a future. ">
<meta property="twitter:image" content="https://dyadxmachina.github.io/can-machines-teach/img/MtoQA.png">



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Teaching Machines: AI and Education</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.0.1" data-path="introduction.html"><a href="introduction.html#digital-education-footprint"><i class="fa fa-check"></i><b>1.0.1</b> Digital Education Footprint</a></li>
<li class="chapter" data-level="1.0.2" data-path="introduction.html"><a href="introduction.html#journeys"><i class="fa fa-check"></i><b>1.0.2</b> Journeys</a></li>
<li class="chapter" data-level="1.0.3" data-path="introduction.html"><a href="introduction.html#human-knowledge-graph"><i class="fa fa-check"></i><b>1.0.3</b> Human Knowledge Graph</a></li>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#ec2qa-network"><i class="fa fa-check"></i><b>1.1</b> EC2QA Network</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#passive-consumption"><i class="fa fa-check"></i><b>1.2</b> Passive Consumption</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#untested-knowledge"><i class="fa fa-check"></i><b>1.3</b> Untested Knowledge</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#predictability"><i class="fa fa-check"></i><b>1.4</b> Predictability</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#teaching-machine"><i class="fa fa-check"></i><b>1.5</b> Teaching Machine</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#the-components"><i class="fa fa-check"></i><b>1.6</b> The components</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#from-data-to-wisdom-dikw"><i class="fa fa-check"></i><b>1.7</b> From Data to Wisdom (DIKW)</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="implementing-a-teaching-machine.html"><a href="implementing-a-teaching-machine.html"><i class="fa fa-check"></i><b>2</b> Implementing a Teaching Machine</a><ul>
<li class="chapter" data-level="2.1" data-path="implementing-a-teaching-machine.html"><a href="implementing-a-teaching-machine.html#problem-formulation"><i class="fa fa-check"></i><b>2.1</b> Problem Formulation</a></li>
<li class="chapter" data-level="2.2" data-path="implementing-a-teaching-machine.html"><a href="implementing-a-teaching-machine.html#why-deep-learning"><i class="fa fa-check"></i><b>2.2</b> Why deep learning?</a></li>
<li class="chapter" data-level="2.3" data-path="implementing-a-teaching-machine.html"><a href="implementing-a-teaching-machine.html#before-we-start"><i class="fa fa-check"></i><b>2.3</b> Before we start…</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="learning-feedback.html"><a href="learning-feedback.html"><i class="fa fa-check"></i><b>3</b> LEARNING + FEEDBACK</a><ul>
<li class="chapter" data-level="3.1" data-path="learning-feedback.html"><a href="learning-feedback.html#question-generation"><i class="fa fa-check"></i><b>3.1</b> Question Generation</a></li>
<li class="chapter" data-level="3.2" data-path="learning-feedback.html"><a href="learning-feedback.html#answer-evaluation"><i class="fa fa-check"></i><b>3.2</b> Answer Evaluation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="learning-feedback.html"><a href="learning-feedback.html#close-ended-questions"><i class="fa fa-check"></i><b>3.2.1</b> Close-ended Questions</a></li>
<li class="chapter" data-level="3.2.2" data-path="learning-feedback.html"><a href="learning-feedback.html#open-ended-question"><i class="fa fa-check"></i><b>3.2.2</b> Open-ended Question</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="knowledge-architect.html"><a href="knowledge-architect.html"><i class="fa fa-check"></i><b>4</b> KNOWLEDGE ARCHITECT</a></li>
<li class="chapter" data-level="5" data-path="mission-mapping.html"><a href="mission-mapping.html"><i class="fa fa-check"></i><b>5</b> MISSION MAPPING</a><ul>
<li class="chapter" data-level="5.1" data-path="mission-mapping.html"><a href="mission-mapping.html#summary-of-learning-and-feedback-networks"><i class="fa fa-check"></i><b>5.1</b> Summary of Learning and Feedback Networks</a></li>
<li class="chapter" data-level="5.2" data-path="mission-mapping.html"><a href="mission-mapping.html#summary-of-current-research-and-needs"><i class="fa fa-check"></i><b>5.2</b> Summary of Current Research and Needs</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="data-and-annotation.html"><a href="data-and-annotation.html"><i class="fa fa-check"></i><b>6</b> Data and Annotation</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dyadxmachina/can-machines-think" target="blank">Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Teaching Machines - Artificial Intelligence and Education</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="learning-feedback" class="section level1">
<h1><span class="header-section-number">3</span> LEARNING + FEEDBACK</h1>
<p>First question first, as we described abobe, we are asking ourselves:</p>
<blockquote>
<p>“how can we take a piece of educational material (i.e. video/ audio recording or e-book) and properly evaluate their learning and provide some effective feedbacks?”.</p>
</blockquote>
<p>Among all the possible evaluation and feedback approaches, <em>Question&amp;Answering</em> framework seems to be one of the most common options.</p>
<p>In achieving this task, it requires a hybrid system that can take the media in use as the input and generate a set of meaningful and relevant question and answer pairs as the output.</p>
<p>In terms of question generation, if the questions generated are close-ended (i.e. multi-choice question), the answers can be defined easily. In turn, the evaluation is relatively easy to accomplish for our system.</p>
<p>To promote the best learning experience and optimal learning outcome, a set of well-diversed questions are the prerequisite. That is to say, it is necessary to also include some open-ended questions i.e. please summarize this video for me in 300 words into our question and answer pool.</p>
<div id="question-generation" class="section level2">
<h2><span class="header-section-number">3.1</span> Question Generation</h2>
<p>The goal of an automatic question generation is to generate a question Q that is syntactically and semantically correct, relevant to the context and meaningful to answer.</p>
<p>In order to achieve this goal,, we need to train an algorithm to learn the underlying conditional probability distribution <span class="math inline">\(P_{\theta}(Q|X)\)</span> parametrized by <span class="math inline">\(\theta\)</span>. Or in other words, we can think of this problem is the one to learn a model <span class="math inline">\(\theta\)</span> during training using text-question pairs so that the probability <span class="math inline">\(P_{\theta}(Q|P)\)</span> is maximized over the given training dataset.</p>
<p>** Case Studies** 1. We can think of it as a seq2seq learning problem; In this paper <a href="http://www.princeton.edu/~shitingl/papers/18l@s-qgen.pdf">QG-Net: A Data-Driven Question Generation Model for Educational Content</a>. They use a bi-directional LSTM network to process the input context words sequence. Encoding the answer into context word vectors.</p>
<p>QG-Net generates questions by iteratively sampling question words from the conditional probability distribution <span class="math inline">\(P(Q|C,A,\theta)\)</span> where <span class="math inline">\(\theta\)</span> denotes the set of parameters. In order to construct the probability distribution, they first create a <strong>context reader</strong> that process each word <span class="math inline">\(c_j\)</span> in the input context and turns it into a fix-sized representation <span class="math inline">\(h_j\)</span></p>
<p>Then, they used a <strong>question generator</strong> generates the question text word-by-word, given all context word representation and all question words in previous time steps.</p>
<p>As for the quantitative evaluation, they aimed to minimize the difference between the generated question and the true question in the training set during training. Also, they used the standard back-propagation through time with the mini-batch stochastic gradient descent algorithm to learn the model parameters. They employed teacher forcing procedure for training LSTMs. To enhance performance, they also implemented beam search, a greedy but effective approximation to exhausitively search and select the top 25 cancidate output question sentences. The final one would be the one with the lowest negative log likelihood.</p>
<p>The general QG-Net model Architecture is as below:</p>
<div class="figure">
<img src="img/qgnet.png" alt="ma" />
<p class="caption">ma</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this summary <a href="http://www.cs.cornell.edu/~xdu/papers/acl17_dsc_poster.pdf">Learning to Ask</a>, they used a sentence- and paragraph-level seq2seq model to read text from the input content and generate a question about the input sentence.</li>
</ol>
<p>For the second option, we need to encode both sentence and paragraph that sentence belongs to as input, but only attending source sentence hidden states. The performance could be improved with beam search and UNK replacement.</p>
<ol start="3" style="list-style-type: decimal">
<li>In this paper <a href="https://openreview.net/pdf?id=rk3pnae0b">TOPIC-BASED QUESTION GENERATION</a>, they proposed a topic-based question generation algorithm. The algorithm will be able to take in a input sentence, a topic and a question type; then generate a word sequence related to the topic, question type and the input sentence.</li>
</ol>
<p>They are formulating a conditional likelihood objective function to achieve this goal.</p>
<p>Also, in the paper, they proposed a few frameworks that were used to tackle this problem. The first type is seq2seq model. This model typically uses a bidirectional LSTM as the encoder to encode a sentence and a LSTM as the decoder to generate the target question. The second approach is question pattern prediction and question topic selection algorithms. It takes in an automatically selected phrase Q and fill this phrase into the pattern that was predicted from pre-mined patterns, which is not done with deep learning.</p>
<p>The last approach is multi-source seq2seq learning which aims to integrate information from multiple sources to boost learning.</p>
<ol start="4" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1808.04961.pdf">A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning</a> they proposed a novel way of solving this problem in which they used a reinforcement learning framework that consists of a generator and an evaluator.</li>
</ol>
<p>They refer to the generator as the <span class="math inline">\(agent\)</span> and the <span class="math inline">\(action\)</span> of the agent is to generate the next work in the question. The probability of decoding a word <span class="math inline">\(P_{\theta}(word)\)</span> gives a stochastic policy.</p>
<p>The evaluator will in turn assign a reward for the output sequence predicted using the current policy of the generator. Based on the reward assigned by the evaluator, the generator updates and improves its current policy. The goal in RL-based question generation is to find a policy that can maximize the sum of the expected return at the end of the sequence generated.</p>
</div>
<div id="answer-evaluation" class="section level2">
<h2><span class="header-section-number">3.2</span> Answer Evaluation</h2>
<div id="close-ended-questions" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Close-ended Questions</h3>
<p><strong>Visual Question Answering (VQA)</strong></p>
<p>As what we have discussed above, most question focuses solely on generating proper questions but not the answers.</p>
<p>VQA aims to enable the machine to answer the question automatically which could in turn automated the whole question generating and evaluation process.</p>
<p>Started from the question-guided attention mechanism that can adaptively learn the most relevant image regions for a given question. Then to stack multiple question-guided attention mechanisms to learn the attention in an iterative way. Also, it is possible to use bilinear features to integrate the visual features from the image spatial grids with question features to predict attention.</p>
<p>Considering the questions in natural language may also contain some noise, the co-attention mechanism can jointly learn the attention for both the image and question.</p>
<ol style="list-style-type: decimal">
<li>In this paper <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.pdf">Deep Attention Neural Tensor Network for Visual Question Answering</a>,</li>
</ol>
<div class="figure">
<img src="img/vqa.png" alt="ma" />
<p class="caption">ma</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1804.02088.pdf">Question Type Guided Attention in Visual Question Answering</a>, they proposed a model called Question Type-guided Attention (QTA). This model utilizes the information of question type to dynamically balance visual features from both top-down and bottom-up orders. Meanwhile, it has a novel neural architecture that dynamically gates the conribution of ResNet and Faster R-CNN features based on the question type.</li>
</ol>
<div id="dual-question-answering-model" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Dual Question-Answering Model</h4>
<p>Both Question Generaion(QG) and Question Answering(QA) are well-defined 2 sets of models that aim to either infer a question or an answer given the counterpart based on the context. However, our goal is to have a complete automated system that can take on both roles simultaneously for us.</p>
<p>There are some algorithms are designed to fulfill both roles. In this paper <a href="https://arxiv.org/pdf/1809.01997.pdf">Dual Ask-Answer Network for Machine Reading Comprehension</a> they presented a model that can learn question answering and question generation simultaneousely.</p>
<p>The idea is illustrate as below: <img src="img/qgqa.png" alt="qgqa" /></p>
<div class="figure">
<img src="img/daan.png" alt="daan" />
<p class="caption">daan</p>
</div>
</div>
</div>
<div id="open-ended-question" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Open-ended Question</h3>
<div id="general-question" class="section level4">
<h4><span class="header-section-number">3.2.2.1</span> General Question</h4>
<p>i.e. Give a summary of this video</p>
<p>At the first glance, it appears hard for our system to effectively evaluate the answers. However, this type of task is not that far-fetched by using some specifically designed deep learning frameworks.</p>
</div>
<div id="specific-question" class="section level4">
<h4><span class="header-section-number">3.2.2.2</span> Specific Question</h4>
<p>As for the automated feedback or learning grading system, there are plenty of suggestions have been proposed as well to tackle such a question. The framework is called automated essay scoring (AES) which focuses on automatically analyzing the quality of writing and assigning a score to the text.</p>
<p>In terms of knowledge or learning evaluation, the format could be diversed i.e. a lecture given by the student or an short summary essay written by the student. Regardless the form, we can always convert the content into a predictable text, graphic or audible format that model can process.</p>
<p>As we mentioned above, for these type of task, we can implementing RNN to process the content and even enhance the model performance by adversarially craft input as this paper <a href="http://aclweb.org/anthology/N18-1024">Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input</a> illustrated. ## Summary of Learning and Feedback Networks</p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="implementing-a-teaching-machine.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="knowledge-architect.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "night",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/dyadxmachina/can-machines-think/edit/master/02-survey.Rmd",
"text": "Edit"
},
"download": ["Teaching Machines - Artificial Intelligence and Education.pdf", "Teaching Machines - Artificial Intelligence and Education.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
