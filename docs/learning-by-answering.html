<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Teaching Machines - Artificial Intelligence and Education</title>
  <meta name="description" content="learn the foundational mathematics required to learn and apply cutting edge deep learning techniques. From Aristolean logic to Jaynes theory of probability to Rosenblatt’s Perceptron and Vapnik's Statistical Learning Theory">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Teaching Machines - Artificial Intelligence and Education" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m4dl.com" />
  <meta property="og:image" content="https://m4dl.comimg/radar.png" />
  <meta property="og:description" content="learn the foundational mathematics required to learn and apply cutting edge deep learning techniques. From Aristolean logic to Jaynes theory of probability to Rosenblatt’s Perceptron and Vapnik's Statistical Learning Theory" />
  <meta name="github-repo" content="dyadxmachina/can-machines-teach" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Teaching Machines - Artificial Intelligence and Education" />
  
  <meta name="twitter:description" content="learn the foundational mathematics required to learn and apply cutting edge deep learning techniques. From Aristolean logic to Jaynes theory of probability to Rosenblatt’s Perceptron and Vapnik's Statistical Learning Theory" />
  <meta name="twitter:image" content="https://m4dl.comimg/radar.png" />

<meta name="author" content="Fanli (Christian) Zheng Ramsey &amp; Haohan Wang">


<meta name="date" content="2018-11-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="concepts.html">
<link rel="next" href="knowledge-architect.html">
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128379860-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-128379860-1');
</script>

<!-- Primary Meta Tags -->
<title>Mathematics for Deep Learning & AI — </title>
<meta name="title" content="Mathematics for Deep Learning & AI — ">
<meta name="description" content="New book on all the mathematics needed to design and implement deep learning systems. From logic to probability to information theory, learn the rigorous mathematics needed to be a deep learning researcher.">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://m4dl.com/">
<meta property="og:title" content="Mathematics for Deep Learning & AI — learn the math needed to design artificial neural networks">
<meta property="og:description" content="New book on all the mathematics needed to design and implement deep learning systems. From logic to probability to information theory, learn the rigorous mathematics needed to be a deep learning researcher.">
<meta property="og:image" content="https://m4dl.com/artwork/maths%20of%20deep%20learning.png">


<!-- Primary Meta Tags -->
<title>Mathematics for Deep Learning & AI — by Haohan Wang and Fanli (Christian) Zheng</title>
<meta name="title" content="Mathematics for Deep Learning & AI — by Haohan Wang and Fanli (Christian) Zheng">
<meta name="description" content="New book on all the mathematics needed to design and implement deep learning systems. From logic to probability to information theory, learn the rigorous mathematics needed to be a deep learning researcher.">

<!-- Open Graph / Facebook -->
<meta property="og:type" content="website">
<meta property="og:url" content="https://m4dl.com/">
<meta property="og:title" content="Mathematics for Deep Learning & AI — by Haohan Wang and Fanli (Christian) Zheng">
<meta property="og:description" content="New book on all the mathematics needed to design and implement deep learning systems. From logic to probability to information theory, learn the rigorous mathematics needed to be a deep learning researcher.">
<meta property="og:image" content="https://m4dl.com/artwork/maths%20of%20deep%20learning.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://m4dl.com/">
<meta property="twitter:title" content="Mathematics for Deep Learning & AI — by Haohan Wang and Fanli (Christian) Zheng">
<meta property="twitter:description" content="New book on all the mathematics needed to design and implement deep learning systems. From logic to probability to information theory, learn the rigorous mathematics needed to be a deep learning researcher.">
<meta property="twitter:image" content="https://m4dl.com/artwork/maths%20of%20deep%20learning.png">

<!-- Twitter -->
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:url" content="https://m4dl.com/">
<meta property="twitter:title" content="Mathematics for Deep Learning & AI ">
<meta property="twitter:description" content="New book on all the mathematics needed to design and implement deep learning systems. From logic to probability to information theory, learn the rigorous mathematics needed to be a deep learning researcher.">
<meta property="twitter:image" content="https://m4dl.com/artwork/maths%20of%20deep%20learning.png">



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Teaching Machines: AI and Education</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="concerns.html"><a href="concerns.html"><i class="fa fa-check"></i><b>2</b> Concerns</a><ul>
<li class="chapter" data-level="2.1" data-path="concerns.html"><a href="concerns.html#passive-consumption"><i class="fa fa-check"></i><b>2.1</b> Passive Consumption</a></li>
<li class="chapter" data-level="2.2" data-path="concerns.html"><a href="concerns.html#untested-knowledge"><i class="fa fa-check"></i><b>2.2</b> Untested Knowledge</a></li>
<li class="chapter" data-level="2.3" data-path="concerns.html"><a href="concerns.html#predictability"><i class="fa fa-check"></i><b>2.3</b> Predictability</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="universal-teaching-machine.html"><a href="universal-teaching-machine.html"><i class="fa fa-check"></i><b>3</b> Universal Teaching Machine</a><ul>
<li class="chapter" data-level="3.1" data-path="universal-teaching-machine.html"><a href="universal-teaching-machine.html#the-components"><i class="fa fa-check"></i><b>3.1</b> The components</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>4</b> Concepts</a><ul>
<li class="chapter" data-level="4.0.1" data-path="concepts.html"><a href="concepts.html#digital-education-footprint"><i class="fa fa-check"></i><b>4.0.1</b> Digital Education Footprint</a></li>
<li class="chapter" data-level="4.0.2" data-path="concepts.html"><a href="concepts.html#journeys"><i class="fa fa-check"></i><b>4.0.2</b> Journeys</a></li>
<li class="chapter" data-level="4.0.3" data-path="concepts.html"><a href="concepts.html#human-knowledge-graph"><i class="fa fa-check"></i><b>4.0.3</b> Human Knowledge Graph</a></li>
<li class="chapter" data-level="4.1" data-path="concepts.html"><a href="concepts.html#from-data-to-wisdom-dikw"><i class="fa fa-check"></i><b>4.1</b> From Data to Wisdom (DIKW)</a></li>
<li class="chapter" data-level="4.2" data-path="concepts.html"><a href="concepts.html#part-i---rethinking-education"><i class="fa fa-check"></i><b>4.2</b> Part I - Rethinking education</a></li>
<li class="chapter" data-level="4.3" data-path="concepts.html"><a href="concepts.html#part-iii---supporting-theories-for-deep-learning"><i class="fa fa-check"></i><b>4.3</b> Part III - Supporting theories for deep learning</a></li>
<li class="chapter" data-level="4.4" data-path="concepts.html"><a href="concepts.html#part-iv---survey-of-empirical-results"><i class="fa fa-check"></i><b>4.4</b> Part IV - Survey of empirical results</a></li>
<li class="chapter" data-level="4.5" data-path="concepts.html"><a href="concepts.html#problem-foumlation"><i class="fa fa-check"></i><b>4.5</b> Problem Foumlation</a></li>
<li class="chapter" data-level="4.6" data-path="concepts.html"><a href="concepts.html#why-deep-learning"><i class="fa fa-check"></i><b>4.6</b> Why deep learning?</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="learning-by-answering.html"><a href="learning-by-answering.html"><i class="fa fa-check"></i><b>5</b> LEARNING by ANSWERING</a><ul>
<li class="chapter" data-level="5.1" data-path="learning-by-answering.html"><a href="learning-by-answering.html#question-generation"><i class="fa fa-check"></i><b>5.1</b> Question Generation</a></li>
<li class="chapter" data-level="5.2" data-path="learning-by-answering.html"><a href="learning-by-answering.html#answer-evaluation"><i class="fa fa-check"></i><b>5.2</b> Answer Evaluation</a><ul>
<li class="chapter" data-level="5.2.1" data-path="learning-by-answering.html"><a href="learning-by-answering.html#close-ended-questions"><i class="fa fa-check"></i><b>5.2.1</b> Close-ended Questions</a></li>
<li class="chapter" data-level="5.2.2" data-path="learning-by-answering.html"><a href="learning-by-answering.html#open-ended-question"><i class="fa fa-check"></i><b>5.2.2</b> Open-ended Question</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="knowledge-architect.html"><a href="knowledge-architect.html"><i class="fa fa-check"></i><b>6</b> KNOWLEDGE ARCHITECT</a></li>
<li class="chapter" data-level="7" data-path="mission-mapping.html"><a href="mission-mapping.html"><i class="fa fa-check"></i><b>7</b> MISSION MAPPING</a><ul>
<li class="chapter" data-level="7.1" data-path="mission-mapping.html"><a href="mission-mapping.html#part-v---call-to-action"><i class="fa fa-check"></i><b>7.1</b> Part V - Call to action</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>8</b> Conclusion</a></li>
<li class="chapter" data-level="9" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>9</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dyadxmachina/can-machines-think" target="blank">Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Teaching Machines - Artificial Intelligence and Education</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="learning-by-answering" class="section level1">
<h1><span class="header-section-number">5</span> LEARNING by ANSWERING</h1>
<div id="question-generation" class="section level2">
<h2><span class="header-section-number">5.1</span> Question Generation</h2>
<p>The goal of an automatic question generation is to generate a question Q that is syntactically and semantically correct, relevant to the context and meaningful to answer.</p>
<p>In order to achieve this goal,, we need to train an algorithm to learn the underlying conditional probability distribution <span class="math inline">\(P_{\theta}(Q|X)\)</span> parametrized by <span class="math inline">\(\theta\)</span>. Or in other words, we can think of this problem is the one to learn a model <span class="math inline">\(\theta\)</span> during training using text-question pairs so that the probability <span class="math inline">\(P_{\theta}(Q|P)\)</span> is maximized over the given training dataset.</p>
<p>** Case Studies** 1. We can think of it as a seq2seq learning problem; In this paper <a href="http://www.princeton.edu/~shitingl/papers/18l@s-qgen.pdf">QG-Net: A Data-Driven Question Generation Model for Educational Content</a>. They use a bi-directional LSTM network to process the input context words sequence. Encoding the answer into context word vectors.</p>
<p>QG-Net generates questions by iteratively sampling question words from the conditional probability distribution <span class="math inline">\(P(Q|C,A,\theta)\)</span> where <span class="math inline">\(\theta\)</span> denotes the set of parameters. In order to construct the probability distribution, they first create a <strong>context reader</strong> that process each word <span class="math inline">\(c_j\)</span> in the input context and turns it into a fix-sized representation <span class="math inline">\(h_j\)</span></p>
<p>Then, they used a <strong>question generator</strong> generates the question text word-by-word, given all context word representation and all question words in previous time steps.</p>
<p>As for the quantitative evaluation, they aimed to minimize the difference between the generated question and the true question in the training set during training. Also, they used the standard back-propagation through time with the mini-batch stochastic gradient descent algorithm to learn the model parameters. They employed teacher forcing procedure for training LSTMs. To enhance performance, they also implemented beam search, a greedy but effective approximation to exhausitively search and select the top 25 cancidate output question sentences. The final one would be the one with the lowest negative log likelihood.</p>
<p>The general QG-Net model Architecture is as below:</p>
<div class="figure">
<img src="img/qgnet.png" alt="ma" />
<p class="caption">ma</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this summary <a href="http://www.cs.cornell.edu/~xdu/papers/acl17_dsc_poster.pdf">Learning to Ask</a>, they used a sentence- and paragraph-level seq2seq model to read text from the input content and generate a question about the input sentence.</li>
</ol>
<p>For the second option, we need to encode both sentence and paragraph that sentence belongs to as input, but only attending source sentence hidden states. The performance could be improved with beam search and UNK replacement.</p>
<ol start="3" style="list-style-type: decimal">
<li>In this paper <a href="https://openreview.net/pdf?id=rk3pnae0b">TOPIC-BASED QUESTION GENERATION</a>, they proposed a topic-based question generation algorithm. The algorithm will be able to take in a input sentence, a topic and a question type; then generate a word sequence related to the topic, question type and the input sentence.</li>
</ol>
<p>They are formulating a conditional likelihood objective function to achieve this goal.</p>
<p>Also, in the paper, they proposed a few frameworks that were used to tackle this problem. The first type is seq2seq model. This model typically uses a bidirectional LSTM as the encoder to encode a sentence and a LSTM as the decoder to generate the target question. The second approach is question pattern prediction and question topic selection algorithms. It takes in an automatically selected phrase Q and fill this phrase into the pattern that was predicted from pre-mined patterns, which is not done with deep learning.</p>
<p>The last approach is multi-source seq2seq learning which aims to integrate information from multiple sources to boost learning.</p>
<ol start="4" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1808.04961.pdf">A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning</a> they proposed a novel way of solving this problem in which they used a reinforcement learning framework that consists of a generator and an evaluator.</li>
</ol>
<p>They refer to the generator as the <span class="math inline">\(agent\)</span> and the <span class="math inline">\(action\)</span> of the agent is to generate the next work in the question. The probability of decoding a word <span class="math inline">\(P_{\theta}(word)\)</span> gives a stochastic policy.</p>
<p>The evaluator will in turn assign a reward for the output sequence predicted using the current policy of the generator. Based on the reward assigned by the evaluator, the generator updates and improves its current policy. The goal in RL-based question generation is to find a policy that can maximize the sum of the expected return at the end of the sequence generated.</p>
</div>
<div id="answer-evaluation" class="section level2">
<h2><span class="header-section-number">5.2</span> Answer Evaluation</h2>
<div id="close-ended-questions" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Close-ended Questions</h3>
<p><strong>Visual Question Answering (VQA)</strong></p>
<p>As what we have discussed above, most question focuses solely on generating proper questions but not the answers.</p>
<p>VQA aims to enable the machine to answer the question automatically which could in turn automated the whole question generating and evaluation process.</p>
<p>Started from the question-guided attention mechanism that can adaptively learn the most relevant image regions for a given question. Then to stack multiple question-guided attention mechanisms to learn the attention in an iterative way. Also, it is possible to use bilinear features to integrate the visual features from the image spatial grids with question features to predict attention.</p>
<p>Considering the questions in natural language may also contain some noise, the co-attention mechanism can jointly learn the attention for both the image and question.</p>
<ol style="list-style-type: decimal">
<li>In this paper <a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Yalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.pdf">Deep Attention Neural Tensor Network for Visual Question Answering</a>,</li>
</ol>
<div class="figure">
<img src="img/vqa.png" alt="ma" />
<p class="caption">ma</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>In this paper <a href="https://arxiv.org/pdf/1804.02088.pdf">Question Type Guided Attention in Visual Question Answering</a>, they proposed a model called Question Type-guided Attention (QTA). This model utilizes the information of question type to dynamically balance visual features from both top-down and bottom-up orders. Meanwhile, it has a novel neural architecture that dynamically gates the conribution of ResNet and Faster R-CNN features based on the question type.</li>
</ol>
<div id="dual-question-answering-model" class="section level4">
<h4><span class="header-section-number">5.2.1.1</span> Dual Question-Answering Model</h4>
<p>Both Question Generaion(QG) and Question Answering(QA) are well-defined 2 sets of models that aim to either infer a question or an answer given the counterpart based on the context. However, our goal is to have a complete automated system that can take on both roles simultaneously for us.</p>
<p>There are some algorithms are designed to fulfill both roles. In this paper <a href="https://arxiv.org/pdf/1809.01997.pdf">Dual Ask-Answer Network for Machine Reading Comprehension</a> they presented a model that can learn question answering and question generation simultaneousely.</p>
<p>The idea is illustrate as below: <img src="img/qgqa.png" alt="qgqa" /></p>
<div class="figure">
<img src="img/daan.png" alt="daan" />
<p class="caption">daan</p>
</div>
</div>
</div>
<div id="open-ended-question" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Open-ended Question</h3>
<p>As for the automated feedback or learning grading system, there are plenty of suggestions have been proposed as well to tackle such a question. The framework is called automated essay scoring (AES) which focuses on automatically analyzing the quality of writing and assigning a score to the text.</p>
<p>In terms of knowledge or learning evaluation, the format could be diversed i.e. a lecture given by the student or an short summary essay written by the student. Regardless the form, we can always convert the content into a predictable text, graphic or audible format that model can process.</p>
<p>As we mentioned above, for these type of task, we can implementing RNN to process the content and even enhance the model performance by adversarially craft input as this paper <a href="http://aclweb.org/anthology/N18-1024">Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input</a> illustrated.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="concepts.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="knowledge-architect.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "night",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/dyadxmachina/can-machines-think/edit/master/01-intro.Rmd",
"text": "Edit"
},
"download": ["Teaching Machines - Artificial Intelligence and Education.pdf", "Teaching Machines - Artificial Intelligence and Education.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
