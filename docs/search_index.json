[
["index.html", "A Knowledge Ecosystem - Deep Learning and Education Preface", " A Knowledge Ecosystem - Deep Learning and Education Fanli (Christian) Zheng &amp; Haohan Wang 2018-11-14 Preface Educational Content to Question-Answer Generation "],
["introduction.html", "1 Introduction", " 1 Introduction Image title Let’s start with a future view of an individual’s education. Many of us have used the internet to educate ourselves with the abundance of medium to high quality videos, papers, articles, podcasts and how-tos being uploaded from numerous individuals, groups, and institutions like never before (60 hours of video are uploaded to youtube.com every minute). Let us imagine that all of what you have learned online, throughout the entirety of your life, from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you’ve read, watched, or listened to, were all added structurally to your very own knowledge journey, and what if that journey could be consolidated into what we might call a knowledge footprint that could be shared with others? Could this replace static degrees? Or augment them to be more inclusive of a learners true knowledge? Our current approach to education is to treat education like a phase as if it only happens in one place. Watching a whole series of Youtube lectures on the Neurobiology of Depression or Discrete Mathematics goes mostly unnoticed when someone views one’s resume or their degree. The ideas behind this knowledge ecosystem, present only one of many possible answers to bringing our education system into modernity. The goal would be to promote the long held idea of the life-long learner. Moving away from getting an education and recognition for a degree, to learning and being continously recognised for seeking to better understand the world for whatever the reason. The goal of the knowledge fingerprint would be to showcase the broad range of a learner’s knowledge (from making digital music to linear algebra) as well as the places they’ve went deeper than most (deep learning or philosophy of mathematics). This footprint, would be stable but always evolving, allowing a learner to update their knowledge while still being comprable to others. So instead of approaching education as a monolithic phase of our lives, this footprint would promote education as a life-long journey. It would also (combined with traditional education) begin to show us a more accurate depiction of a learner’s and theorefore society’s collective knowledge. With every new year, their footprint would evolve and extend just as the very thread of their lives would. Visualised over time, we would be able to see a learner’s knowledge journey. This could also serve as a way for others who may be on similar knowledge journey or those who were looking for a change to find inspiration or be apart of a cohort. You would be able to correlate someone’s life work or occupation to their knowledge journey and eventually begin to find and cluster similar journeys that could emerge through unsupervised learning leading to whole new subjects or journeys that others could follow. In this essay, I will propose a new way to approach education which will require significant effort to bring to life but I believe the benefits will surely outweigh the costs. I’ll talk about how we can use machine learning and deep learning in particular to help create and support our knowledge cosystem which includes a digital knowledge footprint, knowledge journeys, and a collective human knowledge graph. We will also introduce current trends in deep learning and a novel neural network that would allow us to take the space of unstructured educational content and begin to map it unto the human knowledge graph, use generative models to make educational content engaging, and test a learner's knowledge through questions and answers, no what matter the subject. I will name a few benefits of such a future. A society where learners do not simply compete for a degree but where they can feel safe to create their own unique journey through human knowledge and still be recognised and predictable to others A society where a learner’s knowledge is derived not from what we know about a degree but by their actual knowledge which is alive and therefore always evolving A society that better understands itself, through the understanding of the many journey’s it’s members have taken and the collective knowledge that has gone mostly unaccounted for in today’s degree based education. I will also show that this imagined future is not only desirable for society but also that much of it is currently feasible mainly due to the most recent advances in machine learning, and in particular deep learning, which will enable us to begin designing such a future today. *For the purpose of this article we will talk mostly about digital knowledge acquisition and leave the reader to extend the basics to knowledge obtained elsewhere. "],
["concepts.html", "2 Concepts 2.1 Digital Knowledge Footprint 2.2 Knowledge Journeys 2.3 Collective Human Knowledge Graph 2.4 Deep Learning Applications in Learning and Feedback", " 2 Concepts 2.1 Digital Knowledge Footprint The concept of a digital education footprint is is a custom symbol and profile that represents one’s education relative to that of others. Each symbol should be somewhat unique and the profile could capture the general education as well as the intricacies. A symbol which represents somethng as complex as one’s education will likely not be enough for employeers and co-workers to understand the . A symbol must show that one is in a particular “class” while also Symbols generally have to make trade-offs 2.2 Knowledge Journeys Image src: https://www.researchgate.net/figure/t-SNE-projection-of-the-embedding-of-all-learners-in-the-dataset-Major-labels-are_fig1_323391033 between the complexity of what it represents and it’s ability to convey , the legi from dealing with the task of reduction of info. So we introduce Journeys which show how someone has traversed the uy If most people had their digital education footprint, they would be 2.3 Collective Human Knowledge Graph The knowledge graph will be the backbone of a learners journey through human knowledge. As a learner continues to consume educational content, their fingerprint as wethe learner watches new content they extend their knowledge graph either stre current links We have so far introduced knowledge footprint and knowledge journeys, which claim to be the right elements to synthesise one’s education while capturing the complexity on one hand and making the learner relatable and predictable on the other hand. But how does one create a path? From video to video? From topic/subject to topic/subject? If so, how might a machine decide on the correct topic(s)? We have had plenty of advances in topic models but perhaps what we actually need to combine topic models with a graph of human knowledge. This graph, like Google or Wolfram’s knowledge graph, should be generated both from the current structure of education and also driven by the unsupervised learning of new topics/subjects that do not currently exist within our current structure. This graph would be useful so content on the web could be easily mapped to the graph adn relate one user to another as well as create trails. 2.4 Deep Learning Applications in Learning and Feedback 2.4.1 Summary 2.4.2 EC2QA Network - a novel network for educational content to questions and answers The last piece we’ll introduce here is a novel artificial neural network that would allow us to take any unstructured educat "],
["primary-concerns.html", "3 Primary Concerns 3.1 Passive Consumption 3.2 Untested Knowledge 3.3 Predictability", " 3 Primary Concerns There are 3 popular concerns that I will attempt to address in this article about online learning in the present and the future. I will attempt to address them here and in the implementation section below. The first concern is that the learning is often passive The second concern is that the information remains untested and therefore doesn’t truly make the leap from information to true knowledge. The third concern is that even if the two concerns above were met definitively, it would not be possible to . 3.1 Passive Consumption It has been argued and shown in some studies[insert studies], that many people who consume videos or other forms of educational content online, especially when outside the context of school, are often consuming the content passively. This leads to what a colleague called “swiss-cheese learning”, where one learns a bit here and there, lacking any real rigour or depth providing very little probability of capturing the major concepts or mastering the content in any adequate sense. This is a concern that is widely observed. Passive watching is not equivelent to learning. There are many variables that are related to this including those that are cultural and biological. Here I’ll focus on two points. I argue that educational content online expects the content to help a learner reach a particular goal. There is nothing in the content itself, or the platforms, that reach out to reinforce or to verify the knowledge one has gained. I will argue that some key elements of these features that these issues are Engagement can be increased if x, goal directed behaviour can be enhance by small learning goals. Engagement Goal-Directed People watch videos casually and on the fly—and they rarely turn their phones sideways to do it. - Facebook Ads 3.2 Untested Knowledge It has been argued that it is hard to verify what someone has learned while consuming educational content online. This is generally true outside of those content producers who combine content and testing (i.e. Khan Academy, Udacity, Coursera) but they are generally limited compared to the vast amount of videos that are available that lack this testing. The knowledge 3.3 Predictability Concerns #1 and #2 can be solved and it could serve the learner who is seeking to master the content of a particular or several subjects. a learner could find themselves engaging with the goal of mastering the subjects, knowing that their grasp of the knowledge would be tested. But it does not solve the societal issue. If you are like myself, you have watched more videos and read more articles online than you did when you were in school. Possibly much more. But how does one make sense of such consumption since it is largely unstructured and from various learners and institutions. Let us take degrees and their success in making a learner’s ability predictabe. A degree not only makes a learner predictable, in fact, it makes a whole class of learners predictable on one crucial dimension. When we know one has a BA in Mathematics we know that they should have some knowledge of mathematics. We can imagine that a learner with such a degree has working knowledge of a familiar set of subjects (even if one doesn’t know much about mathematics) and also the type of work they might be able to do. This is because of the traditions of our educational institutions and practices. The predictability is due to our past knowledge of what a particular subject is about and the occupational outcomes of such knowledge. The bad part is that degrees are beginning to tell less and less of the story. So for all of it’s ability to reduce the complexity of gained knowledge, it is too limiting to represent a user’s true level of knowledge. "],
["towards-an-ecoystem-of-teaching-machines.html", "4 Towards an ecoystem of teaching machines 4.1 The components", " 4 Towards an ecoystem of teaching machines Image title So how would a universal teaching machine eclipse these challenges? We will present a solution that meets all three criteria by introudcing a theoretical artificial network architecture to cover the first two. neural then cover each concept in detail. Our idea of a digital education footprint, journeys, and a knowledge graph will provide us with what we need to take a first stab at encompassing a learner’s whole education by addressing the three concerns. In order to take all of our videos 4.1 The components A component of a universal teaching machine should be able to take any of the billions of educational content online (and eventualyl off) and by using machine learning and deep learning techniques complete the following: - assign it to a one or more knowledge subjects (i.e. math, design, computer science) - generate a set of adequate questions and answers that test the learner’s (what is x? a, b, c, or d) knowledge throughout the learning session Over time, it is plausible, that our digital education footprint would be the most important representation of a learners level of education. Even more important than our primary education; it has done much to make us predictable, but it has sacrificed the true range of a learner’s gained knowledge and wisdom coming from any other place than the institution is willing to give credit for. Since we’ve largely rely upon large institutions to educate groups of learners, many have grown deeply familiar with having a perfectly demarcated path towards a degree, so it has been much harder for learners to use this abundance of knowledge to chart their own educational journey in today’s fast moving world. being us how to the peer pressure of cohorts, self-learning learned Imagine that if you signed up for a job, your primary consideration and also your digital education could be conveyed as a path through the web that others attempt to follow or mix and match. Now let us imagine a world where our digital education fingerprint allowed us to "],
["theories-for-statistical-learning-theory-and-deep-learning.html", "5 Theories for statistical learning theory and deep learning", " 5 Theories for statistical learning theory and deep learning Theory of the learnable Mutual Information (IT) Joint probability "],
["implementing-the-knowledge-ecosystem.html", "6 Implementing the Knowledge Ecosystem 6.1 Problem Formulation 6.2 Why deep learning? 6.3 Before we start…", " 6 Implementing the Knowledge Ecosystem Here I’ll walk you through the possible implementations of the proposed knowledge ecosystem. I will walk you through the current research in machine learning that is relevant to each component of the knowledge ecosystem and also propose a new artificial neural network architecture called EC2VQA and one possible instansitation of that. This is not the blueprint, each of these components can be developed independently and differ from what you find here. This is a provocation for getting started on the knowledge ecosystem today. How might we approach designing such a system. High level video of all the components in the abstract 6.1 Problem Formulation Building such a digital knowledge ecosystem like the one we just visioned is not a trivial task. We would need to break this ecosystem into few key sub-elements as below so that we can set out to tackle them one by one. LEARNING + FEEDBACK – given a learner consumes a piece of educational material, reliably evaluate their knowledge and provide the feedback for improvement to prevent passive consumption. (credibility, rigour) KNOWLEDGE GRAPH – given a piece of educational content, classify it within a knowledge graph. (relatibility, predictability) KNOLWEDGE JOURNEYS – given multiple student journeys, create a way to customize their own growth journey while offereing a way for them them to compare, connect with and follow, other’s journey (compare, traverse, curiosity) DIGITAL KNOWLEDGE FOOTPRINT – given a student journey, collapse it into a representative symbol(s) to help validate the progress (digital education footprint) [dimensionality reducing (i.e. time, )] (relatibility, stable but evolving system ) Much of the element #1 and #2 have been made possible with the recent breakthoughs in deep learning. A few other pieces like the element #3 and #4 may require a more advanced deep learning framework that has not been proposed yet to best resolve. Let’s first take a look at some methods that might come handy when applying to our problems. 6.2 Why deep learning? If you pay close attention to each of the elements that that we listed above, it is not difficult to identify some shared properties of them that are solvable by machines. Let’s take the first problem as an example, to create a learning and feedback system, we need to first find the relationship between the educational content and the meaningful question &amp; answer pairs that is associated with the content. In other words, our problem could be simplified as trying to find a function that is capable of learning the relationship between our input and output and appropriately map the educational content to the desired question and answer pairs with this function. To the best of our knowledge, deep learning is one of the most optimal techniques currently developed to solve such an issue. First of all, deep learning is known as one of the most flexible machine learning algorithms that can learn and map the deep representation from the data. Moreover, deep nueral networks architecture can be composed into a single differentiable function and trained end-to-end until it converges. As a result, they can help identify the suitable inductive biases catered to the training data. 6.3 Before we start… As what we discussed above, one of the possible and optimal solutions so far for building our ecosystem is using current state-of-art deep learning algorithms in the related domains. Here I will walk you through some thought provinking research summary in a form of survey. To best illustrate the problem and possible solutions, we will for now reduce the complexity of the problem. Keep in mind that our ultimate goal is to be able to apply our system to any type of online available educational content. As what we have mentioned earlier, educational videos seem to be one of the top options for people when it comes to knowledge consumption. Let’s explore some of the solutions that can enable us to apply our system on those video educational content. "],
["learning-feedback.html", "7 LEARNING + FEEDBACK 7.1 Question Generation 7.2 Answer Evaluation 7.3 Summary of Learning and Feedback Networks", " 7 LEARNING + FEEDBACK A salient question that we have to ask ourselves before deisgning such a system is that: “how can we take a piece of educational content and properly test a learners’ knowledge and provide insightful feedbacksto support their learning?”. In previous years, deep learning research has taken up a similar problem titled question answer Question answering (QA) is a well-researched problem in NLP. In spite of being one of the oldest research areas, QA has application in a wide variety of tasks, such as information retrieval and entity extraction. Recently, QA has also been used to develop dialog systems [1] and chatbots [2] designed to simulate human conversation. Traditionally, most of the research in this domain used a pipeline of conventional linguistically-based NLP techniques, such as parsing, part-of-speech tagging and coreference resolution. Many of the state-of-the-art QA systems – for example, IBM Watson [3] –use these methods. src: https://cs224d.stanford.edu/reports/StrohMathur.pdf But this usually only fits the answeringissue given a question . What we want to do is take a piece of content and generate a set of questions-answer pairs. “what types of questions &amp; answers would be best to test a learner’s knowledge given a piece of educational content (i.e. a lecture video)” Let’s say a learner is watching an deducation, then we could n, asking specific questions, or we could allow them to talk abck to us and evaluate their answers. We will approach of these here from the current research and new research needed So the formulation for both of these is to 1. Generate general question + Answers pairs 2. Generate specific question + Answers pairs - Multiple choice 2. Evaluate and comment on open-ended answers Here, we carefully split the questions into 2 distinct categories. One is regular close-ended question (i.e. multiple choise question) and the other one is open-ended question (i.e. tell me about your thoughts on this idea discussed in the video). In terms of the close-ended, the answers can be defined and evaluated easily. However, the process might be a little bit tricky when it comes to the open-ended questions. 7.1 Question Generation First, let’s take a look at question generation (QG) problem on its own. The ideal goal of an automatic question generation is to generate a question Q that is syntactically and semantically correct, relevant to the context and meaningful to answer. In order to achieve this goal,, we need to train an algorithm to learn the underlying conditional probability distribution \\[P_{\\theta}(Q|X)\\] parametrized by \\(\\theta\\). In other words, we can think of this problem as the same one that requires the model learn a function (with a set of parameters) \\(\\theta\\) during the training stage using content-question pairs so that the probability \\(P_{\\theta}(Q|P)\\) is maximized over the given training dataset. It is also helpful to frame this problem into a seq2seq learning problem since both the input and the output is most likely a sequence of text character that the model needs to process and learn the relationship from. Case Studies 1. In this paper QG-Net: A Data-Driven Question Generation Model for Educational Content. They use a bi-directional LSTM network to process the input context words sequence. Encoding the answer into context word vectors. QG-Net generates questions by iteratively sampling question words from the conditional probability distribution \\(P(Q|C,A,\\theta)\\) where \\(\\theta\\) denotes the set of parameters. In order to construct the probability distribution, they first create a context reader that process each word \\(c_j\\) in the input context and turns it into a fix-sized representation \\(h_j\\) Then, they used a question generator generates the question text word-by-word, given all context word representation and all question words in previous time steps. As for the quantitative evaluation, they aimed to minimize the difference between the generated question and the true question in the training set during training. Also, they used the standard back-propagation through time with the mini-batch stochastic gradient descent algorithm to learn the model parameters. They employed teacher forcing procedure for training LSTMs. To enhance performance, they also implemented beam search, a greedy but effective approximation to exhausitively search and select the top 25 cancidate output question sentences. The final one would be the one with the lowest negative log likelihood. The general QG-Net model Architecture is as below: ma In this summary Learning to Ask, they used a sentence- and paragraph-level seq2seq model to read text from the input content and to generate a question about the input sentence. For the second option, we need to encode both sentence and paragraph that sentence belongs to as input, but only attending source sentence hidden states. The performance could be improved with beam search and UNK replacement. In this paper TOPIC-BASED QUESTION GENERATION, they proposed a topic-based question generation algorithm. The algorithm will be able to take in a input sentence, a topic and a question type; then generate a word sequence related to the topic, question type and the input sentence. They are formulating a conditional likelihood objective function to achieve this goal. Also, in the paper, they proposed a few frameworks that were used to tackle this problem. The first type is seq2seq model. This model typically uses a bidirectional LSTM as the encoder to encode a sentence and a LSTM as the decoder to generate the target question. The second approach is question pattern prediction and question topic selection algorithms. It takes in an automatically selected phrase Q and fill this phrase into the pattern that was predicted from pre-mined patterns, which is not done with deep learning. The last approach is multi-source seq2seq learning which aims to integrate information from multiple sources to boost learning. In this paper A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning they proposed a novel way of solving this problem in which they used a reinforcement learning framework that consists of a generator and an evaluator. They refer to the generator as the \\(agent\\) and the \\(action\\) of the agent is to generate the next work in the question. The probability of decoding a word \\(P_{\\theta}(word)\\) gives a stochastic policy. The evaluator will in turn assign a reward for the output sequence predicted using the current policy of the generator. Based on the reward assigned by the evaluator, the generator updates and improves its current policy. The goal in RL-based question generation is to find a policy that can maximize the sum of the expected return at the end of the sequence generated. ** Summary ** In this QG section, we have discussed 4 algorithms. They provide us a way to frame our problem for which we can apply generative seq2seq model framework. As for our objective function, we are formuating a conditional probability distribution that is conditioned on the provided content (i.e. the video) and answers. Typically, we can use a bi-directional LSTM as the encoder to encode the content and use a LSTM as the decoder to generate the question. 7.2 Answer Evaluation 7.2.1 Close-ended Questions Visual Question Answering (VQA) As what we have covered above, most QG problem focuses solely on generating questions but not the answers based on the context. VQA is a challenging sementic task that focuses on providing a natural language answer given any image and any free-form natural language question. As we are managing to handle the video educational content that is likely to involve language processing and visual recognition tasks, VQA would be a proper and relevant start. By leveraging this type of algorithm, we enable our system to easily evaluate the answer provided by learners which could in turn automated the whole question + answering + evaluation cycle. Since we are dealing with visual input, question-guided attention mechanism is a key component for solving this type of task. Started from the attention mechanism that can adaptively learn the most relevant image regions for a given question. Then to stack multiple question-guided attention mechanisms to learn the attention in an iterative way. Also, it is possible to use bilinear features to integrate the visual features from the image spatial grids with question features to predict attention. Considering the questions in natural language may also contain some noise, the co-attention mechanism can jointly learn the attention for both the image and question. In this paper Deep Attention Neural Tensor Network for Visual Question Answering, they proposed a novel deep attention neural tensor network that can discover the joint correlation over images, questions and answers with tensor-based representation. As for their workflow, they modeled one of the pairwise interaction (i.e. between image and question) by bilinear features, which is further encoded with the thrid dimension (i.e. answer) to be a triplet using bilinear tensor product. During this step, the model takes in a question + a corresponding image + candidate answers as the input. A CNN (convolutional neural network) a GRU RNN (recurrent neural network) are used for extracting feature vectors and question respectively. Then the representation is passed on as a multi-modal features and integrated by bilinear pooling module. Moreover, they decompose the correlation of triplets by their question and answer types with a slice-wise attention module on tensor to select the most discriminative reasoning process inference. In the end, they optimize the proposed network by learning a label regression with KL-divergence losses. They clamined that with these techniques, they can enable scalable training and fast convergence over a large number of answer set. During the inference stage, they feed the embeddings of all candicate answer into the network and then select the answer which has the biggest triplet relevance socre as the final answer. The general network architecture is as follows: ma In this paper Question Type Guided Attention in Visual Question Answering, they proposed a model called Question Type-guided Attention (QTA). This model utilizes the information of question type to dynamically balance visual features from both top-down and bottom-up orders. Finally, they propose a multi-task extension that is trained to predict question types from the lexical inputs during training which generalizes the network into applications that lack question type, with a minimal performance loss. As for their main contribution, they focus on developing an attention mechanism that can exploit high-level semantic information on the question type to guide the visual encoding process. Specifically, they introduced a novel VQA architecture that can dynamically gate the contribution of ResNet and Faster R-CNN features based on the question type. In turn, it allows them to integrate the information from multiple visual sources and obtain gains across all question types. Summary By going through the previous examples, we can see that VQA is very particular type of algorithms that is designed to efficiently process image and text input data while making the inference based on the input. Attention is a typical mechanism applied in this type of problems. 7.2.1.1 Dual Question-Answering Model Both Question Generaion(QG) and Question Answering(QA) are well-defined 2 sets of models that aim to either infer a question or an answer given the counterpart based on the context. However, our goal is to have a complete automated system that can take on both roles simultaneously for us. There are some algorithms are designed to fulfill both roles. 1.In this paper Dual Ask-Answer Network for Machine Reading Comprehension they presented a model that can learn question answering and question generation simultaneousely. The idea is illustrate as below: qgqa daan In this paper Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia, they applied their question-answer pair generation system to 10000 top-ranking Wikipedia articles and create over a million question-answer pairs. In their task formulation part, they mentioned that they break this task into 2 sub-tasks: candidate answer extraction answer-specific question generation In this paper Visual Question Generation as Dual Task of Visual Question Answering, they proposed an end-to-end unified model, Invertible Question Answering (iQAN) to introduce question generation as a dual task of question answering to imrpove VQA pefromance. In this paper A Unified Query-based Generative Model for Question Generation and Question Answering, they propose a query-based generative model for solving both tasks. The model follows the classic encoder-decoder framework. The multi-perspective matching encoder that they are implementing is a bi-directional LSTM RNN model that takes a passage and a query as input and perform query understanding by matching it with the passage from multiple perspectives; The decoder is an attention-based LSTM RNN model with copy and coverage mechanism. In the QG task, a question will be generated from the model given the passge and the target answer, whereas in the QA task, the answer will be generated given the question and the passage. They also leverage a policy-gradient reinforcement learning algorithm to overcome exposure bias (a major problem resulted from sequence learning with cross-entropy loss function).They case both QG and QA tasks into one process by firstly matching the input passage against the query, then generating the output based on the matching results. As for the training process, they first pretrain the model with cross-entropy loss and then they fine tune the model parameters with policy-gradient reinforcement learning to alleviate the exposure bias problem. During the policy-gradient reinforcement learning algorithm, they end up adopting a similar sampling strategy as the scheduled sampling strategy for generating the sampled output. Summary As what have discussed above, we can see that there have been many attemps taken in the recent years for handling both tasks at the same time and some significant progress have been made. 7.2.2 Open-ended Question Summary of #### General Question As I mentioned aboce, one of the most general open-ended questions is to ask learner to provide a short summary of the learning material. At the first glance, it appears hard for our system to effectively evaluate the answers. However, this type of task is not that far-fetched by using some specifically designed deep learning frameworks. 7.2.2.1 Specific Question As for the automated feedback or learning grading system, there are plenty of suggestions have been proposed as well to tackle such a question. The framework is called automated essay scoring (AES) which focuses on automatically analyzing the quality of writing and assigning a score to the text. In terms of knowledge or learning evaluation, the format could be diversed i.e. a lecture given by the student or an short summary essay written by the student. Regardless the form, we can always convert the content into a predictable text, graphic or audible format that model can process. As we mentioned above, for these type of task, we can implementing RNN to process the content and even enhance the model performance by adversarially craft input as this paper Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input illustrated. 7.3 Summary of Learning and Feedback Networks 7.3.1 summary current research 7.3.2 areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area] 7.3.3 datasets and annotaters needed "],
["knowledge-graph.html", "8 KNOWLEDGE GRAPH 8.1 Summary of Knowledge Graph", " 8 KNOWLEDGE GRAPH Next, we need to consider how we can select an adequate and relevant learning masterial and generate an effecive learning map for the learners based on their current progress and the general knowledge graph/map, given the ever growing amount of educational content on the web. As I mentioned earlier, learning is a knowledge accumulation process. Knowledge itself has its unique structure that can help us learn in a most effective and productive way. Knowledge Graph is a great tool that we developed to map and present the structure of knolwedge. In shirt, knowledge graphs are collections of relational facts, where each fact states that a certrain relation holds between 2 entities. In this paper Generalized Embedding Model for Knowledge Graph Mining, they have presented a model for learning neural presentation of generalized knowledge graphs using a novel muli-shot unsupervised neural network model, called the Graph Embedding Network (GEN). This model is able to learn different types of knowlege graphs from a universal perspective and it provides flexibility in learning representations that work on graphs conforming to different domains. In this paper Probabilisic Knowledge Graph Embeddings, they explored a new type of embedding model that can link prediction in relational knowledge graph. In this paper Zero-Shot Question Generation from Knowledge Graphs for Unseen Predicates and Entity Types, they presented a network that can generate question from knowledge b 8.1 Summary of Knowledge Graph 8.1.1 summary current research 8.1.2 areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area] 8.1.3 datasets and annotaters needed "],
["knowledge-journeys-1.html", "9 KNOWLEDGE JOURNEYS", " 9 KNOWLEDGE JOURNEYS The knowledge graph is our ground truth and can be applied universally to some extent, but everyone’s learning journey is still highly personal and custom. In terms of learning, everyone seems to have their unique set of problems that they are curious about and everyone is on their own mission towards the mastery. We cannot possibly put such an online learning/teaching system into use without taking this crucial factor into our account. In order to put our hands on this set of problems, we can rely on some heuristic and models that have been developed to resolve this type of idiosymcratic issue. As we all know that a recommender system is an intuitive line of defense against consumer over-choice given the evern growing information available on the web. As we mentioned earlier in the knowledge graph, a authoritative and personalized recommending system is essential for facilitating the learning. Typically, a recommendation models can be classified into 3 main categories: Collaborative filtering Content based Hybrid recommender system As I mentioned, here we will mainly focus on hybrid recommender system. There are a diverse array of achitectual paradigms that are closely related recommending system. Let’s take a look at few of them: 1. Autoencoder Convolutional Neural Network Recurrent Neural Network Restricted Boltzmann Machine (RBM) Adversarial Networks Attentional Models (AM) Deep Reinforcement Learning (DRL) "],
["digital-knowledge-footprint-1.html", "10 DIGITAL KNOWLEDGE FOOTPRINT 10.1 Summary of Current Research and Needs", " 10 DIGITAL KNOWLEDGE FOOTPRINT 10.1 Summary of Current Research and Needs "],
["data-and-annotation.html", "11 Data and Annotation", " 11 Data and Annotation Reference A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning Learning to Ask: Neural Question Generation for Reading Comprehension Deep Attention Neural Tensor Network for Visual Question Answering Learning to Ask TOPIC-BASED QUESTION GENERATION Deep Learning based Recommender System "]
]
