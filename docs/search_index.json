[
["index.html", "A Knowledge Ecosystem - Deep Learning and Education Preface", " A Knowledge Ecosystem - Deep Learning and Education Fanli (Christian) Zheng &amp; Haohan Wang 2018-11-14 12:07:34 Preface Educational Content to Question-Answer Generation "],
["introduction.html", "1 Introduction", " 1 Introduction Image title Let’s start with a future view of an individual’s education. Many of us have used the internet to educate ourselves with the abundance of medium to high quality videos, papers, articles, podcasts and how-tos being uploaded from numerous individuals, groups, and institutions like never before (60 hours of video are uploaded to youtube.com every minute). Let us imagine that all of what you have learned online, throughout the entirety of your life, from the hundreds of Youtube videos, Wikipedia articles, Nature papers, and podcasts you’ve read, watched, or listened to, were all added structurally to your knowledge journey, and what if that journey could be consolidated into what we might call a knowledge footprint that could be shared with others? Could this replace static degrees? Or augment them to be more inclusive of a learner’s true knowledge? Our current approach to education is to treat knowledge acquisition like a chapter in the individual’s life that is limited to one or more formal places. This is misleading since we accrue knowledge from everywhere and most recently the internet has become a primary source of knowledge acquisition but has gone mostly unaccounted for in terms of recognition (i.e. watching a whole series of Youtube lectures on the Neurobiology of Depression or Discrete Mathematics goes mostly unnoticed when someone views one’s resume or by simply looking at their degree.). This makes it much harder for people to switch to working and exploring outside of their degree area. Knowing rigourous mathematics and not having a degree in it, is said to be surprising, therefore the current “thumbnail view” of an individual’s knowlede is neccessarily inadequate to the new mediums of knowledge acquisition. Example at aminer The ideas behind this knowledge ecosystem, presents only one of many possible solutions to bringing our education system into modernity. The goal of it would be to promote the long held idea of the life-long learner. Moving away from the “education chapter”&quot; of an individual’s life to the individual as an evolving learner; learning the necessary skills for what life presents them with today or might tomorrow. It would (combined with traditional education) show us a more accurate depiction of a learner’s knowledge and theorefore that of a society’s collective knowledge. Visualised over time, we could begin to capture a learner’s so called knowledge journey. Composed of every piece of content they’ve gained knowledge from mapped to the human knowledge graph. Showing how an individual has traversed through the world of human knowledge. This would also serve as a way for others, who may be on a similar knowledge journey to connect with their cohort. This could be the start of meetups, study groups, and so on. For those who are looking for a change, they may find different journeys that help them decide what step to take next. You would also be able to connect someone’s occupation to their knowledge journey. On aggregate, we could begin to cluster similar knowledge journeys through unsupervised learning, which might lead to completely new journeys or combinations of subjects that others could attempt to follow. In this essay, I will propose a knowledge ecosystem, a new way of approaching education that attempts to build a more accurate depiction of a learner’s true knowledge. It will require significant effort to bring to life but I believe the benefits will outweigh the costs. I will talk about how we can use machine learning, deep learning in particular, to help create and support our knowledge ecosystem which is made up of a knowledge footprint, knowledge journeys, and a collective human knowledge graph. We will also introduce current advances in deep learning that would enable us to take the space of unstructured educational content and begin to map it unto the human knowledge graph, and how we can use generative models to test a learner's knowledge of recently viewed educationcal content through questions and answers, no what matter the subject. I will name a few benefits of such a future. A society where learners do not simply compete for a degree but where they can feel safe to create their own unique journey through human knowledge whilst being recognised and predictable to others A society where a learner’s knowledge is derived not from what we know about a degree but by their actual knowledge which is alive and therefore always evolving A society that better understands itself, through the understanding of the many journey’s it’s members have taken I will also show that this imagined future is not only desirable for society but a required future for an individual to match the pace at which we are advancing. Let us not forget, that even software engineering is being recreated with machine learning as a key pillar which has happened seemingly overnight. It is tantamount that we have adaptative systems that can represent our knowledge and make us predictable even as we hasten the pace at which the indiivdual learns, the future pushes us to know more than we’ve ever known and to be able to learn quicker than we once did This hypothetical future isn’t just conceptual, most of what I will present t you today is currently feasible due to the most recent advances in machine learning, and in particular deep learning, which will enable us to begin designing such a future today. I will end this essay with a call to action. *For the purpose of this essay we will talk mostly about digital knowledge acquisition and leave the reader to extend the basics to knowledge obtained elsewhere. "],
["primary-concerns.html", "2 Primary Concerns 2.1 Knowledge Ecosystem Example 2.2 Passive Consumption and Untested Knowledge 2.3 The Problem of Knowledge Representation", " 2 Primary Concerns There are 3 popular concerns that I will attempt to address in this article about online learning in the present and near future. I will attempt to address them here and in the implementation section. The first concern we have is Passive Consumption - most of online content is viewed passively by the learner and the result of passive consumption is that learner’s do not grasp the concepts or master the content being taught. Untested Knowledge - even if the learner was engaged while viewing a piece of educational content their knowledge is untested and therefore it isn’t clear if they’ve mastered the content accurately and in some sense holistically. Knowledge Representation - even if the learner was engaged and their knowledge was tested, simply knowing the counts or types of video they watched doesn’t make their knowledge predictable and useful to others. In fact, most people are unaware of all the content they’ve consumed over the years and cannot synthesise it as well as they possible could. 2.1 Knowledge Ecosystem Example Knowledge Ecosystem Let us put forward an example the matches each of these concerns. But in order to do so we need to lay out the our eco In order to address the concerns above we have put together the basic components of this knowledge system. We have also mentioned that we will focus on the digital aspects as we believe it presents the biggest leap forward for knowledge representation. An ecosystem 2.2 Passive Consumption and Untested Knowledge How would such an ecosystem insure us against passive consumption? As you can see, I’ve bundled passive consumption and untested knowledge because our proposed system approaches both of these by always testing knowledge. Given a piece of educational content, our knowledge system will generate a set of questions and answers that theoretically capture the major concepts and facts that the learner should know after viewing a part or the content in whole. You can imagine watching a Youtube video and after a learner views 15 minutes of an hour long lecture on computational complexity a quiz is presented (a set of questions and answers conditioned on the past 15 minutes of video,) and the results are recorded. In the future we would also be able to use the knowledge graph The knowledge system would only consider content that has been watched with some engagement or if they can test out of the content. 2.3 The Problem of Knowledge Representation "],
["concepts.html", "3 Concepts 3.1 Digital Knowledge Footprint 3.2 Knowledge Journeys 3.3 Collective Human Knowledge Graph 3.4 Deep Learning Applications in Learning and Feedback", " 3 Concepts 3.1 Digital Knowledge Footprint The concept of a digital education footprint is is a custom symbol and profile that represents one’s education relative to that of others. Each symbol should be somewhat unique and the profile could capture the general education as well as the intricacies. A symbol which represents somethng as complex as one’s education will likely not be enough for employeers and co-workers to understand the . A symbol must show that one is in a particular “class” while also Symbols generally have to make trade-offs 3.2 Knowledge Journeys Image src: https://www.researchgate.net/figure/t-SNE-projection-of-the-embedding-of-all-learners-in-the-dataset-Major-labels-are_fig1_323391033 between the complexity of what it represents and it’s ability to convey , the legi from dealing with the task of reduction of info. So we introduce Journeys which show how someone has traversed the uy If most people had their digital education footprint, they would be 3.3 Collective Human Knowledge Graph The knowledge graph will be the backbone of a learners journey through human knowledge. As a learner continues to consume educational content, their fingerprint as wethe learner watches new content they extend their knowledge graph either stre current links We have so far introduced knowledge footprint and knowledge journeys, which claim to be the right elements to synthesise one’s education while capturing the complexity on one hand and making the learner relatable and predictable on the other hand. But how does one create a path? From video to video? From topic/subject to topic/subject? If so, how might a machine decide on the correct topic(s)? We have had plenty of advances in topic models but perhaps what we actually need to combine topic models with a graph of human knowledge. This graph, like Google or Wolfram’s knowledge graph, should be generated both from the current structure of education and also driven by the unsupervised learning of new topics/subjects that do not currently exist within our current structure. This graph would be useful so content on the web could be easily mapped to the graph adn relate one user to another as well as create trails. 3.4 Deep Learning Applications in Learning and Feedback 3.4.1 Summary 3.4.2 EC2QA Network - a novel network for educational content to questions and answers The last piece we’ll introduce here is a novel artificial neural network that would allow us to take any unstructured educat "],
["implementing-the-knowledge-ecosystem.html", "4 Implementing the Knowledge Ecosystem 4.1 Problem Formulation 4.2 Before we start…", " 4 Implementing the Knowledge Ecosystem In this section, we are set to solve the following question: How might we approach designing such a system. I will walk you through some possible implementations of the proposed knowledge ecosystem. I will be presenting the current research in machine learning that is relevant to each component of the knowledge ecosystem and also discuss this new artificial neural network architecture EC2VQA and one possible instansitation of that. Note that this is not the blueprint, each of these components can be developed independently and vary from what you find here. This is a provocation for getting started on the knowledge ecosystem today. 4.1 Problem Formulation Building such a digital knowledge ecosystem like the one we just visioned is not a trivial task. We would need to break this ecosystem into few key sub-elements as below so that we can set out to tackle them one by one. LEARNING + FEEDBACK – given a learner consumes a piece of educational content, reliably evaluate their knowledge and provide the feedback for improvement to support their learning. (credibility, rigour) KNOWLEDGE GRAPH – general knowledge blueprint as a map to piece together all the content that is currently available. (relatibility, predictability) KNOWLEDGE JOURNEYS – given a piece of educational content, classify it within a knowledge graph; given multiple learner journeys, create a way to customize their own growth journey while offereing a way for them them to compare, connect with and follow, other’s journey (compare, traverse, curiosity) KNOWLEDGE FOOTPRINT – given a learner’s journey, collapse it into a representative symbol(s) (digital education footprint) (relatibility, stable but evolving system ) Much of the element #1 and #2 have been made possible with the recent breakthoughs in machine learning especially in the filed of deep learning. A few other pieces like the element #3 and #4 may require a more advanced framework that has not been proposed yet to best resolve. Let’s first take a look at some methods that might come handy when applying to our problems. 4.2 Before we start… As what we discussed above, one of the possible and optimal solutions so far for building our ecosystem is using current state-of-art deep learning algorithms in the related domains. Here I will walk you through some thought provinking research summary in a form of survey. To best illustrate the problem and possible solutions, we will for now reduce the complexity of the problem. Keep in mind that our ultimate goal is to be able to apply our system to any type of online available educational content. As what we have mentioned earlier, educational videos seem to be one of the top options for people when it comes to knowledge consumption. Let’s explore some of the solutions that can enable us to apply our system on those video educational content. "],
["learning-feedback.html", "5 LEARNING + FEEDBACK 5.1 Why deep learning? 5.2 Question Generation 5.3 Answer Generation 5.4 Summary of Learning and Feedback Networks", " 5 LEARNING + FEEDBACK A salient question that we have to ask ourselves before deisgning such a system is that: “how can we take a piece of educational content and properly test a learners’ knowledge and provide insightful feedbacks to support their learning?”. In previous years, deep learning research has taken up a similar problem titled Question Generation (QG) and Question Answering (QA). Question Generation (QG) is part of NLP. The goal of QG is to generate questions according to some given information. It could be used in many different scenarios i.e. generating questions for reading comprehension, generating data from large scale question-answering pairs or even generating questions from images. Earlier approaches to QG mainly used human-crafted rules and patterns to transform a descriptive sentence to a related question. Recent neural network-based approaches represent the state-of-art of most of those tasks and this approach has been successfully applied to many other NLP tasks i.e. neural machine translation, summarization, etc. As the training optimization studies progress, the stability and performance improvements are gauranteed. As for Question Answering (QA) task, it is a well-researched problem in NLP as well. Recently, QA has also been used to develop dialog systems and chatbots designed to simulate human conversation. Traditionally, most of the research used a pipeline of conventional linguistically-based NLP techniques i.e. parsing, part-of-speech tagging and coreference resolution. However, with recent developments in deep learning, neural network models have shown promise for QA. Further improvement i.e.attention mechanism and memory networks allow the network to focus on the most revevant facts such that they achieved state-of-art performance for QA. Now we have some basic understanding of these 2 problems that we will be investigaing more in depth later. Consider the next question: “what types of questions &amp; answers would be best to test a learner’s knowledge given a piece of educational content (i.e. a lecture video)” Let’s say a learner is watching a video about hypothesis testing, after showing an example and given the data needed to test the hypothesis. Then the system will pause the video and ask: What is the p-value for this test? (and provide multiple choices for learner to choose from) Is this a 1-sided test? (answers provided would be: YES or NO) How would you intepret the p-value in the context of this example. Based on your calculation, summarize the conclusion of this hypothesis testing for me. It is also ideal to ask learner the question as follows after showing the solution and explanation: Tell me what you have learned through this example. As shown above, we would call questions #1 and #2 close-ended questions; question #3 and #4 specific open-ended questions; and question #5 a general open-ended question. So the formulation for both of these is to: Generate close-ended question + Answers pairs Generate specific open-ended question + Answers pairs Evaluate and comment on the general open-ended answers In terms of the close-ended, the answers can be well defined and evaluated. However, the process might be a little bit tricky when it comes to the open-ended questions. We will approach each of them here from the current research. 5.1 Why deep learning? As we stated above, deep learning has achieved state-of-art performance in both QG and QA tasks. Now let’s take a close look at why. If you pay close attention to the question generation and answer generation set of problems, we can easily frame this problem into a general machine learning problem in which we need to find the relationship between the educational content and the meaningful question &amp; answer pairs that is associated with the content. In other words, our problem could be simplified as learning a function that is capable of capture the relationship between our input and output, that is to say, appropriately map the educational content to the desired question and answer pairs with this function. To the best of our knowledge, deep learning is one of the most optimal techniques currently developed to solve such an issue. As we all know that machine learninag is a set of algorithms that can be used to parse data, learn from the data, and then apply what they have learned to make intelligent decisions. Or more specifically, Deep learning is a subset of machine learning and it belongs to a family of representation learning. Inside this family, deep learning is good at sampling the features and have additonal layers for more abstract feature learning which will support the final goal of mapping the feature to the output. Because of the above advantages, deep learning is known as one of the most flexible machine learning algorithms that can learn and map the deep representation from the data. Also, deep nueral networks architecture can be composed into a single differentiable function and trained end-to-end until it converges. As a result, they can help identify the suitable inductive biases catered to the training data. Moreover, deep learning outperforms other techniques when the training data size is large which fits our siutation well. We have a large amound of educational content that is currently available on the web. The large amount content creates another problem that can be avoided with deep learning as well, which is it’s going to very troublesome to do feature engineering manually. When there is lack of domain understanding for feature introspection, deep learning is preferable. In the end, deep learning really shines when it comes to many complex reserach problems such as NLP, Visual Recognition and Speech recognition. For solving our task, all those domians will possibly be invloved. 5.2 Question Generation First, let’s take a look at question generation (QG) problem. The ideal goal of an automatic question generation is to generate a question Q that is syntactically and semantically correct, relevant to the context and meaningful to answer. In order to achieve this goal,, we need to train an algorithm to learn the underlying conditional probability distribution \\[P_{\\theta}(Q|X)\\] parametrized by \\(\\theta\\). In other words, we can think of this problem as the same one that requires the model learn a function (with a set of parameters) \\(\\theta\\) during the training stage using content-question pairs so that the probability \\(P_{\\theta}(Q|P)\\) is maximized over the given training dataset. It is also helpful to frame this problem into a seq2seq learning problem since both the input and the output is most likely a sequence of text character that the model needs to process and learn the relationship from. 5.2.1 Case Studies In this paper QG-Net: A Data-Driven Question Generation Model for Educational Content. They use a bi-directional LSTM network to process the input context words sequence. Encoding the answer into context word vectors. QG-Net generates questions by iteratively sampling question words from the conditional probability distribution \\(P(Q|C,A,\\theta)\\) where \\(\\theta\\) denotes the set of parameters. In order to construct the probability distribution, they first create a context reader that process each word \\(c_j\\) in the input context and turns it into a fix-sized representation \\(h_j\\) Then, they used a question generator generates the question text word-by-word, given all context word representation and all question words in previous time steps. As for the quantitative evaluation, they aimed to minimize the difference between the generated question and the true question in the training set during training. Also, they used the standard back-propagation through time with the mini-batch stochastic gradient descent algorithm to learn the model parameters. They employed teacher forcing procedure for training LSTMs. To enhance performance, they also implemented beam search, a greedy but effective approximation to exhausitively search and select the top 25 cancidate output question sentences. The final one would be the one with the lowest negative log likelihood. The general QG-Net model Architecture is as below: ma In this summary Learning to Ask, they used a sentence- and paragraph-level seq2seq model to read text from the input content and to generate a question about the input sentence. For the second option, we need to encode both sentence and paragraph that sentence belongs to as input, but only attending source sentence hidden states. The performance could be improved with beam search and UNK replacement. In this paper TOPIC-BASED QUESTION GENERATION, they proposed a topic-based question generation algorithm. The algorithm will be able to take in a input sentence, a topic and a question type; then generate a word sequence related to the topic, question type and the input sentence. They are formulating a conditional likelihood objective function to achieve this goal. Also, in the paper, they proposed a few frameworks that were used to tackle this problem. The first type is seq2seq model. This model typically uses a bidirectional LSTM as the encoder to encode a sentence and a LSTM as the decoder to generate the target question. The second approach is question pattern prediction and question topic selection algorithms. It takes in an automatically selected phrase Q and fill this phrase into the pattern that was predicted from pre-mined patterns, which is not done with deep learning. The last approach is multi-source seq2seq learning which aims to integrate information from multiple sources to boost learning. In this paper A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning they proposed a novel way of solving this problem in which they used a reinforcement learning framework that consists of a generator and an evaluator. They refer to the generator as the \\(agent\\) and the \\(action\\) of the agent is to generate the next work in the question. The probability of decoding a word \\(P_{\\theta}(word)\\) gives a stochastic policy. The evaluator will in turn assign a reward for the output sequence predicted using the current policy of the generator. Based on the reward assigned by the evaluator, the generator updates and improves its current policy. The goal in RL-based question generation is to find a policy that can maximize the sum of the expected return at the end of the sequence generated. 5.2.2 Summary In this QG section, we have discussed 4 algorithms. They provide us a way to frame our problem for which we can apply generative seq2seq model framework. As for our objective function, we are formuating a conditional probability distribution that is conditioned on the provided content (i.e. the video) and answers. Typically, we can use a bi-directional LSTM as the encoder to encode the content and use a LSTM as the decoder to generate the question. However, as you probabily have noticed that the above examples are focus mainly on processing the text input data instead of videos directly. It demonstrates that more reserch in this new area is needed so as to meet our particular needs. 5.3 Answer Generation 5.3.1 Close-ended Questions 5.3.1.1 Visual Question Answering (VQA) As what we have covered above, most QG problem focuses solely on generating questions but not the answers based on the context. VQA is a challenging research problem that focuses on providing a natural language answer given any image and any free-form natural language question. As we are managing to handle the video educational content first that is likely to involve language processing and visual recognition tasks, VQA would be a proper start for us. By leveraging this type of algorithm, we enable our system to easily evaluate the answer provided by learners which could in turn automated the whole question + answering + evaluation cycle. Since we are dealing with visual input, question-guided attention mechanism is a key component for solving this type of task. Started from the attention mechanism that can adaptively learn the most relevant image regions for a given question. Then to stack multiple question-guided attention mechanisms to learn the attention in an iterative way. Also, it is possible to use bilinear features to integrate the visual features from the image spatial grids with question features to predict attention. Considering the questions in natural language may also contain some noise, the co-attention mechanism can jointly learn the attention for both the image and question. In this paper Deep Attention Neural Tensor Network for Visual Question Answering, they proposed a novel deep attention neural tensor network that can discover the joint correlation over images, questions and answers with tensor-based representation. As for their workflow, they modeled one of the pairwise interaction (i.e. between image and question) by bilinear features, which is further encoded with the thrid dimension (i.e. answer) to be a triplet using bilinear tensor product. During this step, the model takes in a question + a corresponding image + candidate answers as the input. A CNN (convolutional neural network) a GRU RNN (recurrent neural network) are used for extracting feature vectors and question respectively. Then the representation is passed on as a multi-modal features and integrated by bilinear pooling module. Moreover, they decompose the correlation of triplets by their question and answer types with a slice-wise attention module on tensor to select the most discriminative reasoning process inference. In the end, they optimize the proposed network by learning a label regression with KL-divergence losses. They clamined that with these techniques, they can enable scalable training and fast convergence over a large number of answer set. During the inference stage, they feed the embeddings of all candicate answer into the network and then select the answer which has the biggest triplet relevance socre as the final answer. The general network architecture is as follows: ma In this paper Question Type Guided Attention in Visual Question Answering, they proposed a model called Question Type-guided Attention (QTA). This model utilizes the information of question type to dynamically balance visual features from both top-down and bottom-up orders. Finally, they propose a multi-task extension that is trained to predict question types from the lexical inputs during training which generalizes the network into applications that lack question type, with a minimal performance loss. As for their main contribution, they focus on developing an attention mechanism that can exploit high-level semantic information on the question type to guide the visual encoding process. Specifically, they introduced a novel VQA architecture that can dynamically gate the contribution of ResNet and Faster R-CNN features based on the question type. In turn, it allows them to integrate the information from multiple visual sources and obtain gains across all question types. 5.3.1.2 Video Question Answering The recent advancements that we discussed above in VQA domain have shown some promising implication. In terms of achieving our particular goal, it is also worth mentioning that VQA might be a good start but it is not sufficient yet. To bridge this gap, let’s focus our attention on some video question answering algorithms that have been proposed. 5.3.1.3 Summary By going through the previous examples, we can see that VQA is very particular type of algorithms that is designed to efficiently process image and text input data while making the inference based on the input. Attention is a typical mechanism applied in this type of problems and multiple forms of multipulation on the attention mechanism used in these models have significantly improved the model performance. In turn, we can conclude that 5.3.1.4 Dual Question-Answering Model Both Question Generaion(QG) and Question Answering(QA) are well-defined 2 sets of models that aim to either infer a question or an answer given the counterpart based on the context. However, our goal is to have a complete automated system that can take on both roles simultaneously for us. There are some algorithms are designed to fulfill both roles. 1.In this paper Dual Ask-Answer Network for Machine Reading Comprehension they presented a model that can learn question answering and question generation simultaneousely. The general architecture of the model is illustrate as below: qgqa daan In this paper Harvesting Paragraph-Level Question-Answer Pairs from Wikipedia, they applied their question-answer pair generation system to 10000 top-ranking Wikipedia articles and create over a million question-answer pairs. In their task formulation part, they mentioned that they break this task into 2 sub-tasks: candidate answer extraction answer-specific question generation In this paper Visual Question Generation as Dual Task of Visual Question Answering, they proposed an end-to-end unified model, Invertible Question Answering (iQAN) to introduce question generation as a dual task of question answering to imrpove VQA pefromance. In this paper A Unified Query-based Generative Model for Question Generation and Question Answering, they propose a query-based generative model for solving both tasks. The model follows the classic encoder-decoder framework. The multi-perspective matching encoder that they are implementing is a bi-directional LSTM RNN model that takes a passage and a query as input and perform query understanding by matching it with the passage from multiple perspectives; The decoder is an attention-based LSTM RNN model with copy and coverage mechanism. In the QG task, a question will be generated from the model given the passge and the target answer, whereas in the QA task, the answer will be generated given the question and the passage. They also leverage a policy-gradient reinforcement learning algorithm to overcome exposure bias (a major problem resulted from sequence learning with cross-entropy loss function).They case both QG and QA tasks into one process by firstly matching the input passage against the query, then generating the output based on the matching results. As for the training process, they first pretrain the model with cross-entropy loss and then they fine tune the model parameters with policy-gradient reinforcement learning to alleviate the exposure bias problem. During the policy-gradient reinforcement learning algorithm, they end up adopting a similar sampling strategy as the scheduled sampling strategy for generating the sampled output. Summary As what have discussed above, we can see that there have been many attemps taken in the recent years for handling both tasks at the same time and some significant progress have been made. 5.3.2 Open-ended Question 5.3.2.1 General Question As I mentioned aboce, one of the most general open-ended questions is to ask learner to provide a short summary of the learning content. At the first glance, it appears hard for our system to effectively evaluate the answers. However, this type of task is not that far-fetched by using some specifically designed deep learning frameworks. 5.3.2.2 Specific Question As for the automated feedback or learning grading system, there are plenty of suggestions have been proposed as well to tackle such a question. The framework is called automated essay scoring (AES) which focuses on automatically analyzing the quality of writing and assigning a score to the text. In terms of knowledge or learning evaluation, the format could be diversed i.e. a lecture given by the learner or an short summary essay written by the learner. Regardless the form, we can always convert the content into a predictable text, graphic or audible format that model can process. As we mentioned above, for these type of task, we can implementing RNN to process the content and even enhance the model performance by adversarially craft input as this paper Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input illustrated. 5.4 Summary of Learning and Feedback Networks 5.4.1 summary current research 5.4.2 areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area] 5.4.3 datasets and annotaters needed "],
["knowledge-graph.html", "6 KNOWLEDGE GRAPH 6.1 Summary of Knowledge Graph", " 6 KNOWLEDGE GRAPH Next, we need to consider how we can select an adequate and relevant learning masterial and generate an effecive learning map for the learners based on their current progress and the general knowledge graph/map, given the ever growing amount of educational content on the web. As I mentioned earlier, learning is a knowledge accumulation process. Knowledge itself has its unique structure that can help us learn in a most effective and productive way. Knowledge Graph is a great tool that we developed to map and present the structure of knolwedge. In shirt, knowledge graphs are collections of relational facts, where each fact states that a certrain relation holds between 2 entities. In this paper Generalized Embedding Model for Knowledge Graph Mining, they have presented a model for learning neural presentation of generalized knowledge graphs using a novel muli-shot unsupervised neural network model, called the Graph Embedding Network (GEN). This model is able to learn different types of knowlege graphs from a universal perspective and it provides flexibility in learning representations that work on graphs conforming to different domains. In this paper Probabilisic Knowledge Graph Embeddings, they explored a new type of embedding model that can link prediction in relational knowledge graph. In this paper Zero-Shot Question Generation from Knowledge Graphs for Unseen Predicates and Entity Types, they presented a network that can generate question from knowledge b 6.1 Summary of Knowledge Graph 6.1.1 summary current research 6.1.2 areas where new stuff needs to be made research [current reserach is promising but we need more reserach and innovation in this area] 6.1.3 datasets and annotaters needed "],
["knowledge-journeys-1.html", "7 KNOWLEDGE JOURNEYS", " 7 KNOWLEDGE JOURNEYS The knowledge graph is our ground truth and can be applied universally to some extent, but everyone’s learning journey is still highly custom. In terms of learning, everyone seems to have their unique set of problems that they are curious about and everyone is on their own mission towards the mastery. As a result, their knowlege journeys could have a lot more degree of freedom depends on the learn’s learning history, interests and who they are related to. We cannot possibly put such an online learning/teaching system into use without taking this crucial factor into our account. However, this is not a trivial problem that can be solved with 1 network or 2. Let’s first formulate our problem before we dive into the possible solutions. Below are few key components that we need to combine to achieve our ultimate goal which is to appropriately guide the learner through their unique knowledge journey: First, we need to , we can rely on some heuristic and models that have been developed to resolve this type of idiosymcratic issue. As we all know that a recommender system is an intuitive line of defense against consumer over-choice given the evern growing information available on the web. As we mentioned earlier in the knowledge graph, a authoritative and personalized recommending system is essential for facilitating the learning. Typically, a recommendation models can be classified into 3 main categories: Collaborative filtering Content based Hybrid recommender system As I mentioned, here we will mainly focus on hybrid recommender system. There are a diverse array of achitectual paradigms that are closely related recommending system. Let’s take a look at few of them: 1. Autoencoder Convolutional Neural Network Recurrent Neural Network Restricted Boltzmann Machine (RBM) Adversarial Networks Attentional Models (AM) Deep Reinforcement Learning (DRL) "],
["digital-knowledge-footprint-1.html", "8 DIGITAL KNOWLEDGE FOOTPRINT 8.1 Summary of Current Research and Needs", " 8 DIGITAL KNOWLEDGE FOOTPRINT [dimensionality reducing (i.e. time, )] 8.1 Summary of Current Research and Needs "],
["data-and-annotation.html", "9 Data and Annotation", " 9 Data and Annotation Some datasets used for QG prpblem: SQuAD RACE Typical datasets used for VQA research: VQA dataset that consists of 2 subsets: real images and abstract scenes. Compositional Language and Elementary Visual Reasoning (CLEVR) diagnostic dataset that focuses on reasoning. Task Driven Image Understanding Challenge dataset (TDIUC); it contains images and annotations from MSCOCO and Visual genome. Reference A Framework for Automatic Question Generation from Text using Deep Reinforcement Learning Learning to Ask: Neural Question Generation for Reading Comprehension Deep Attention Neural Tensor Network for Visual Question Answering Learning to Ask TOPIC-BASED QUESTION GENERATION Deep Learning based Recommender System "],
["conclusion.html", "10 Conclusion 10.1 Datasets and Annotation 10.2 New Network", " 10 Conclusion In conclusion, 10.1 Datasets and Annotation 10.2 New Network "],
["about-authors.html", "11 About Authors 11.1 Haohan Wang 11.2 Fanli (Christian) Zheng", " 11 About Authors 11.1 Haohan Wang 11.2 Fanli (Christian) Zheng "],
["links.html", "12 Links", " 12 Links "]
]
